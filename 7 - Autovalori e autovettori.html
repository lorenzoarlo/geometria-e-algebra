<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link rel="stylesheet" href="styles/style.css" />  
    <title>7 - Autovalori e autovettori</title>
</head>
<body>
    
    <div class="content">
        <div class="section part" id="sec7" ><span class="section-header part-title">7 - Autovalori e autovettori</span><div class="subsection part" id="subsec7-1" ><span class="subsection-header part-title">7.1 - Autovalori, autovettori e autospazi</span><div class="definition environment" id="def7-1" ><span class="definition-header environment-title">Definizione 7.1 - Insieme <span class="math-tag">\( U_{\lambda}\)</span></span>     L'insieme <span class="math-tag">\( U_{\lambda}\)</span>, associato ad un endomorfismo <span class="math-tag">\( f: V \to V\)</span>, è l'insieme composto da tutti i vettori la cui immagine <span class="math-tag">\( \lambda\)</span> volte il vettore, ovvero     <span class="math-tag">\[         U_{\lambda} = \{ v \in V \ : \ f(v) = \lambda \cdot v \}     \]</span></div><div class="demonstration environment" id="dem7-1" ><span class="demonstration-header environment-title">Dimostrazione 7.1 - <span class="math-tag">\( U_{\lambda}\)</span> come sottospazio vettoriale</span>     Data la proposizione     <div class="proposition environment" ><span class="proposition-header environment-title">Enunciato</span>         L'insieme <span class="math-tag">\( U_{\lambda}\)</span> associato ad un endomorfismo <span class="math-tag">\( f: V \to V\)</span> è un sottospazio vettoriale di <span class="math-tag">\( V\)</span>.     </div><div class="proof environment" ><span class="proof-header environment-title">Dimostrazione:</span>         Per dimostrare tale proposizione è necessario verificare che il vettore somma di due vettori e il vettore prodotto per uno scalare appartengono sempre ad <span class="math-tag">\( U_{\lambda}\)</span>.         <br ></br>         Consideriamo quindi <span class="math-tag">\( v, w \in U_{\lambda}\)</span> e <span class="math-tag">\( \alpha, \beta \in \mathbb{R}\)</span>, e scriviamo per linearità che         <span class="math-tag">\begin{aligned}             & f(\alpha \cdot v + \beta \cdot w) = \alpha \cdot f(v) + \beta \cdot f(w)              & \iff         \end{aligned}</span>         Ora, dato che <span class="math-tag">\( v, w\)</span> appartengono ad <span class="math-tag">\( U_{\lambda}\)</span>, sappiamo che la loro immagine è         <span class="math-tag">\begin{aligned}             & f(\alpha \cdot v + \beta \cdot w) = \alpha \cdot (\lambda \cdot v) + \beta \cdot (\lambda \cdot w)             & \iff         \end{aligned}</span>         allora per la proprietà distributiva si può scrivere         <span class="math-tag">\begin{aligned}             & f(\alpha \cdot v + \beta \cdot w) = \lambda \cdot (\alpha \cdot v + \beta \cdot w)             &          \end{aligned}</span>         che verifica la proposizione.     </div><div class="mynote environment" ><span class="mynote-header environment-title">Osservazioni personali - <span class="math-tag">\( U_{\lambda}\)</span> e il vettore nullo</span>         Come tutti i sottospazi vettoriali, <span class="math-tag">\( U_{\lambda}\)</span> non è mai vuoto perchè contiene sempre almeno il vettore nullo.     </div></div><div class="definition environment" id="def7-2" ><span class="definition-header environment-title">Definizione 7.2 - Autovalori, autovettori e autospazi</span>     Considerando un insieme <span class="math-tag">\( U_{\lambda}\)</span> associato ad un endomorfismo <span class="math-tag">\( f: V \to V\)</span>, se contiene vettori diversi dal vettore nullo (che è sempre presente), si dice che <span class="math-tag">\( U_{\lambda}\)</span> è un autospazio e <span class="math-tag">\( \lambda\)</span> un autovalore.     <br ></br>     Tutti vettori che fanno parte di un autospazio, sono detti autovettori.        <div class="mynote environment" ><span class="mynote-header environment-title">Osservazioni personali - Attenzione!</span>         Si sta quindi dicendo che anche il vettore nullo è un autovettore, ma solo se appartiene ad <span class="math-tag">\( U_{\lambda}\)</span> insieme ad altri vettori. In questo modo è possibile dire che ogni autospazio è un sottospazio vettoriale. Da notare che alcune definizioni non considerano mai il vettore nullo come un autovettore.     </div></div><div class="definition environment" id="def7-3" ><span class="definition-header environment-title">Definizione 7.3 - Trovare gli autovettori</span>     Considerando una matrice <span class="math-tag">\( A \in M_{B_{V}, B_{V}}(f)\)</span> associata ad un endomorfismo <span class="math-tag">\( f: V \to V\)</span>, si ha che l'immagine di un autovettore <span class="math-tag">\( v\)</span> attraverso <span class="math-tag">\( f\)</span> può essere scritta come     <span class="math-tag">\begin{aligned}         & A \odot X = \lambda \cdot X         & \iff     \end{aligned}</span>     dove <span class="math-tag">\( X\)</span> è la <span class="math-tag">\( n\)</span>-upla di coordinate di <span class="math-tag">\( v\)</span>.     <br ></br>     Allora per trovare tutti gli autovettori associati ad un certo autovalore <span class="math-tag">\( \lambda\)</span> si può raggiungere la seguente forma     <span class="math-tag">\begin{aligned}         & A \odot X - \lambda \cdot X = 0          & \iff \\         & (A - \lambda \cdot I) \odot X = 0         &     \end{aligned}</span>     che rappresenta un sistema lineare omogeneo.     <br ></br>           Considerando <span class="math-tag">\( A \in M_{\mathcal{B}, \mathcal{B}}(f)\)</span> la matrice associata ad un endomorfismo <span class="math-tag">\( f\)</span> e <span class="math-tag">\( \lambda \in \mathbb{R}\)</span>, si dice matrice caratteristica la matrice <span class="math-tag">\( (A - \lambda I)\)</span>.     <br ></br>     Il determinante di questa matrice è un polinomio nella variabile <span class="math-tag">\( \lambda\)</span> ed è detto polinomio caratteristico di grado <span class="math-tag">\( n\)</span>. </div><div class="definition environment" id="def7-4" ><span class="definition-header environment-title">Definizione 7.4 - Matrice caratteristica e polinomio caratteristico</span>     Considerando una matrice <span class="math-tag">\( A \in M_{B_{V}, B_{V}}(f)\)</span> associata ad un endomorfismo <span class="math-tag">\( f: V \to V\)</span>, la matrice <span class="math-tag">\( A - \lambda \cdot I\)</span> si dice matrice caratteristica e il suo determinante, un polinomio nella variabile <span class="math-tag">\( \lambda\)</span> di grado <span class="math-tag">\( n\)</span>, è detto polinomio caratteristico.     <div class="mynote environment" ><span class="mynote-header environment-title">Osservazioni personali - Polinomio, tell me more</span>         Il polinomio caratteristico <span class="math-tag">\( p_{A}(\lambda)\)</span> ci informa sia della traccia che del determinante di <span class="math-tag">\( A\)</span>, infatti scritto nella forma         <span class="math-tag">\[             p_{A}(\lambda) = \lambda^{n} + (-1)^{n - 1} \cdot k \cdot \lambda^{n - 1} + \ \ldots \ + m         \]</span>         si ha che il coefficiente <span class="math-tag">\( k\)</span> di <span class="math-tag">\( \lambda^{n - 1}\)</span> è la traccia di <span class="math-tag">\( A\)</span> mentre il coefficiente <span class="math-tag">\( m\)</span> è il determinante di <span class="math-tag">\( A\)</span>.     </div></div><div class="demonstration environment" id="dem7-2" ><span class="demonstration-header environment-title">Dimostrazione 7.2 - Polinomio caratteristico di due matrici simili</span>     Data la proprietà     <div class="proposition environment" ><span class="proposition-header environment-title">Enunciato</span>         Considerando due matrici <span class="math-tag">\( A, B \in M_{n \times n}(\mathbb{K})\)</span> simili allora il polinomio di tali matrici è lo stesso, ovvero         <span class="math-tag">\[             A \sim B              \qquad \implies \qquad              p_{A}(\lambda) = p_{B}(\lambda)          \]</span></div><div class="proof environment" ><span class="proof-header environment-title">Dimostrazione:</span>         Per definizione, si ha che         <span class="math-tag">\begin{aligned}             & p_{B}(\lambda) = p_{E^{-1} \odot A \odot E}(\lambda) = det((E^{-1} \odot A \odot E) - \lambda I)             & \iff         \end{aligned}</span>         Dato che <span class="math-tag">\( E^{-1} \odot E = I\)</span> e che il prodotto per uno scalare è commutativo, si può scrivere che         <span class="math-tag">\begin{aligned}             & det(E^{-1} \odot A \odot E - (E^{-1} \odot (\lambda I) \odot E))             & \iff         \end{aligned}</span>         e per la distributività si può raccogliere <span class="math-tag">\( E^{-1}\)</span> a sinistra ed <span class="math-tag">\( E\)</span> a destra, ottenendo così         <span class="math-tag">\begin{aligned}             & det(E^{-1} \odot (A - (\lambda I)) \odot E)             & \iff         \end{aligned}</span>         Ora, grazie al teorema di Binet, si può scrivere         <span class="math-tag">\begin{aligned}             & det(E^{-1}) \cdot det(A - \lambda I) \cdot det(E)             & \iff         \end{aligned}</span>         ed ora, grazie alla commutatività del prodotto tra scalari si può ottenere         <span class="math-tag">\begin{aligned}             & det(E^{-1}) \cdot det(E) \cdot det(A - \lambda I)             & \iff         \end{aligned}</span>         che è esattamente il polinomio caratteristico di <span class="math-tag">\( A\)</span>, in quanto         <span class="math-tag">\begin{aligned}             & det(A - \lambda I) = p_{A}(\lambda)             &         \end{aligned}</span>         Si è quindi dimostrata la proposizione.     </div></div><div class="demonstration environment" id="dem7-3" ><span class="demonstration-header environment-title">Dimostrazione 7.3 - Teorema - Determinante nullo della matrice caratteristica come condizione necessaria e sufficiente affinchè <span class="math-tag">\( \lambda\)</span> sia un autovalore</span>     Dato il teorema     <div class="proposition environment" ><span class="proposition-header environment-title">Enunciato</span>         Il numero <span class="math-tag">\( \lambda \in \mathbb{R}\)</span> è un autovalore di <span class="math-tag">\( f\)</span> se e solo se il determinante della matrice caratteristica <span class="math-tag">\( (A - \lambda I)\)</span> è <span class="math-tag">\( 0\)</span>.      </div><div class="proof environment" ><span class="proof-header environment-title">Dimostrazione:</span>         Per dimostrare tale teorema è necessario dimostrare che         <ul ><li >"se <span class="math-tag">\( \lambda\)</span> è un autovalore di <span class="math-tag">\( f\)</span>, allora il determinante della matrice caratteristica <span class="math-tag">\( (A - \lambda I)\)</span> è <span class="math-tag">\( 0\)</span>". Considerando che <span class="math-tag">\( A\)</span> è la matrice associata ad <span class="math-tag">\( f\)</span> e <span class="math-tag">\( X\)</span> le coordinate di un qualsiasi vettore <span class="math-tag">\( v \in V\)</span>, si ha che             <span class="math-tag">\begin{aligned}                 & A \odot X = \lambda \cdot X                 & \iff             \end{aligned}</span>             Affinchè <span class="math-tag">\( \lambda\)</span> sia un autovalore è necessario che <span class="math-tag">\( U_{\lambda}\)</span> contenga altri vettori oltre a quello nullo. Per provarlo, possiamo scrivere l'espressione precedente come             <span class="math-tag">\begin{aligned}                 & A \odot X = \lambda I \odot X                 & \iff             \end{aligned}</span>             e aggiungere da "entrambe le parti" l'opposto di <span class="math-tag">\( \lambda I \odot X\)</span> ottenendo             <span class="math-tag">\begin{aligned}                 & A \odot X - \lambda I \odot X = 0                 & \iff             \end{aligned}</span>             che per l'associatività è possibile scrivere come             <span class="math-tag">\begin{aligned}                 & (A - \lambda I) \odot X = 0                 &              \end{aligned}</span>             Considerando quindi questa espressione come un sistema lineare, si ha che <span class="math-tag">\( (A - \lambda I)\)</span> non deve avere rango massimo (altrimenti si avrebbe un'unica soluzione) ovvero il suo determinante deve essere nullo;             </li><li >"se il determinante della matrice caratteristica (<span class="math-tag">\( A - \lambda I\)</span>) è <span class="math-tag">\( 0\)</span>, allora <span class="math-tag">\( \lambda\)</span> è un autovalore di <span class="math-tag">\( f\)</span>". Supponiamo per assurdo che <span class="math-tag">\( \lambda\)</span> non sia autovalore di <span class="math-tag">\( f\)</span> : ciò implica che <span class="math-tag">\( U_{\lambda}\)</span> sia composto dal solo vettore nullo, ovvero che non esiste vettore non nullo <span class="math-tag">\( X\)</span> tale che             <span class="math-tag">\begin{aligned}                 & \nexists X \neq 0 \ : \ A \odot X = \lambda \cdot X                 & \iff             \end{aligned}</span>             Continuando su questa via, si può aggiungere "da entrambe le parti" l'opposto di <span class="math-tag">\( \lambda \cdot X\)</span>, ottenendo             <span class="math-tag">\begin{aligned}                 & A \odot X - \lambda \cdot X = 0                 & \iff             \end{aligned}</span>             e raccogliendo <span class="math-tag">\( X\)</span> per la proprietà distributiva si ottiene             <span class="math-tag">\begin{aligned}                 & (A \odot - \lambda \cdot I) \odot X = 0                 & \iff             \end{aligned}</span>             che rappresenta un sistema lineare. Dato che sappiamo che il determinante di <span class="math-tag">\( A \odot - \lambda \cdot I\)</span> è <span class="math-tag">\( 0\)</span>, sappiamo che il suo rango non è massimo (ovvero <span class="math-tag">\( < n\)</span> come minimo). Dato che la dimensione dello spazio delle soluzioni è dato da             <span class="math-tag">\[                 dim(Sol(S) = n - (< n) = (> 0)              \]</span>             si otterrebbe che la dimensione dello spazio delle soluzioni è maggiore di <span class="math-tag">\( 0\)</span> che è un assurdo, in quanto sappiamo che la dimensione dello spazio delle soluzioni deve essere <span class="math-tag">\( 0\)</span> (ovvero deve essere composto solo dal vettore nullo).         </li></ul>         Si è quindi dimostrato il teorema.     </div></div><div class="myexample environment" id="example40" ><span class="myexample-header environment-title">Esempio 40 - Calcolo degli autovalori, autospazi e autovettori</span>     Considerando l'endomorfismo <span class="math-tag">\( f: \mathbb{R}^{2} \to \mathbb{R}^{2}\)</span><span class="math-tag">\[         f((x, y)) = (2x - y, 2x + 5y)     \]</span>     e la matrice associata ad <span class="math-tag">\( f\)</span> rispetto alla base canonica     <span class="math-tag">\[         A = M_{\varepsilon, \varepsilon}(f) =          \left(         \begin{array}{cc}             2 & -1 \\             2 & 5         \end{array}         \right)     \]</span>     si vogliono trovare gli autovalori, gli autospazi e gli autovettori di <span class="math-tag">\( f\)</span>.     <br ></br>     Scriviamo quindi la matrice caratteristica     <span class="math-tag">\[         A - \lambda I =          \left(         \begin{array}{cc}             2 & -1 \\             2 & 5         \end{array}         \right)         -         \left(         \begin{array}{cc}             \lambda & 0 \\             0 & \lambda         \end{array}         \right)         =          \left(         \begin{array}{cc}             2 - \lambda & -1 \\             2 & 5 - \lambda         \end{array}         \right)     \]</span>     Il determinante di <span class="math-tag">\( A - \lambda I\)</span> è     <span class="math-tag">\[         det(A - \lambda I) = (2 - \lambda) \cdot (5 - \lambda) - (-1 \cdot 2) = \lambda^{2} - 7 \lambda + 12     \]</span>     Per trovare i valori per cui il determinante si annulla basta calcolare le radici, ovvero     <span class="math-tag">\[         \lambda_{1, 2} = \frac{7 \pm \sqrt{49 - 48}}{2}          \quad \implies \quad          \left\{         \begin{array}{lcl}            \lambda_{1}  & = & \frac{7 + 1}{2} = 4 \\            \lambda_{2}  & = & \frac{7 - 1}{2} = 3         \end{array}         \right.     \]</span>     Abbiamo quindi ottenuto che gli autovalori di <span class="math-tag">\( f\)</span> sono <span class="math-tag">\( 3\)</span> e <span class="math-tag">\( 4\)</span>.     <br ></br>     Per calcolare gli autospazi è sufficiente sostituire alla matrice caratteristica il valore di <span class="math-tag">\( \lambda\)</span> e risolvere il sistema lineare:     <dl ><dd ><dt>(<span class="math-tag">\( \lambda = 3\)</span>)</dt> si ha quindi         <span class="math-tag">\begin{aligned}             & (A - \lambda I)              \odot              X = 0             & \iff \\             & \left(             \begin{array}{cc}                 2 - \lambda & -1 \\                 2 & 5 - \lambda             \end{array}             \right)             \odot X = 0             & \iff \\             &             \left(             \begin{array}{cc}                 -1 & -1 \\                 2 & 2             \end{array}             \right)             \odot              \left(             \begin{array}{c}                 x \\                  y             \end{array}             \right)             =              \left(             \begin{array}{c}                 0 \\                  0             \end{array}             \right)             & \iff \\             & \left\{             \begin{array}{ccccc}                 -x & - & y & = & 0  \\                 2x & + & 2y & = & 0             \end{array}             \right.         \end{aligned}</span>         la cui soluzione è <span class="math-tag">\(          \left(         \begin{array}{c}             s \\             -s         \end{array}         \right)         \)</span>, ovvero si ha che <span class="math-tag">\( U_{3} = \{ (s, -s) : s \in \mathbb{R} \}\)</span> che è equivalente a scrivere <span class="math-tag">\( <(1, -1)>\)</span>.         </dd><dd ><dt>(<span class="math-tag">\( \lambda = 4\)</span>)</dt> si ha quindi         <span class="math-tag">\begin{aligned}             & (A - \lambda I)              \odot              X = 0             & \iff \\             & \left(             \begin{array}{cc}                 2 - \lambda & -1 \\                 2 & 5 - \lambda             \end{array}             \right)             \odot X = 0             & \iff \\             &             \left(             \begin{array}{cc}                 -2 & -1 \\                 2 & 1             \end{array}             \right)             \odot              \left(             \begin{array}{c}                 x \\                  y             \end{array}             \right)             =              \left(             \begin{array}{c}                 0 \\                  0             \end{array}             \right)             & \iff \\             & \left\{             \begin{array}{ccccc}                 -2x & - & y & = & 0  \\                 2x & + & y & = & 0             \end{array}             \right.         \end{aligned}</span>         la cui soluzione è <span class="math-tag">\(          \left(         \begin{array}{c}             s \\             -2s         \end{array}         \right)         \)</span>, ovvero si ha che <span class="math-tag">\( U_{4} = \{ (s, -2s) : s \in \mathbb{R} \}\)</span> che è equivalente a scrivere <span class="math-tag">\( <(1, -2)>\)</span>.     </dd></dl>     Abbiamo quindi trovato gli autovalori, gli autospazi e gli autovettori. </div><div class="demonstration environment" id="dem7-4" ><span class="demonstration-header environment-title">Dimostrazione 7.4 - Autovalori per le composizioni di <span class="math-tag">\( f^{n}\)</span></span>     Data la proposizione     <div class="proposition environment" ><span class="proposition-header environment-title">Enunciato</span>         Considerando <span class="math-tag">\( v\)</span> un autovettore associato ad un autovalore <span class="math-tag">\( \lambda\)</span>, si ha che all'<span class="math-tag">\( n\)</span>-esima composizione di <span class="math-tag">\( f\)</span> sarà associato l'autovettore <span class="math-tag">\( \lambda^{n}\)</span>, ovvero         <span class="math-tag">\[             f(v) = \lambda \cdot v             \qquad             \implies             \qquad             f^{n}(v) = \lambda^{n} \cdot v         \]</span></div><div class="proof environment" ><span class="proof-header environment-title">Dimostrazione:</span>         Considerando la composizione <span class="math-tag">\( f^{n}\)</span> dell'endomorfismo <span class="math-tag">\( f\)</span>, si ha che         <span class="math-tag">\[            f_{1} \circ \ldots \circ f_{n} = \lambda \cdot f^{n-1}(v) = \lambda^{n} \cdot v         \]</span>         che dimostra la proposizione.     </div></div><div class="definition environment" id="def7-5" ><span class="definition-header environment-title">Definizione 7.5 - Elemento nullo come autovalore solo di funzioni non iniettive</span><span class="math-tag">\( \lambda = 0\)</span> è un autovalore di <span class="math-tag">\( f\)</span> se e solo se <span class="math-tag">\( f\)</span> è non iniettiva.     <div class="mynote environment" ><span class="mynote-header environment-title">Osservazioni personali - Logica della dimostrazione</span>         Ciò è evidente anche dal fatto che se <span class="math-tag">\( \lambda = 0\)</span> fosse un autovalore, l'immagine di molti vettori sarebbe la stessa. Si avrebbe infatti <span class="math-tag">\( f(v) = 0 \cdot v = 0_{V}\)</span> per ogni vettore di <span class="math-tag">\( V\)</span>.      </div></div><div class="demonstration environment" id="dem7-5" ><span class="demonstration-header environment-title">Dimostrazione 7.5 - Autovalori e autovettori dell'inverso di un endomorfismo</span>     Data la proposizione     <div class="proposition environment" ><span class="proposition-header environment-title">Enunciato</span>         Considerando un endomorfismo <span class="math-tag">\( f\)</span> invertibile, se <span class="math-tag">\( v\)</span> è un autovettore per <span class="math-tag">\( f\)</span>, esso lo è anche per <span class="math-tag">\( f^{-1}\)</span> e l'autovalore ad esso associato è <span class="math-tag">\( \frac{1}{\lambda}\)</span>.     </div><div class="proof environment" ><span class="proof-header environment-title">Dimostrazione:</span>         Per dimostrare tale proposizione, consideriamo che         <span class="math-tag">\[             f(v) = \lambda \cdot v              \qquad \implies \qquad             v = f^{-1}(\lambda v)          \]</span>         allora è possibile scrivere         <span class="math-tag">\begin{aligned}             & v = f^{-1}(\lambda v)             & \iff         \end{aligned}</span>         e per la linearità di <span class="math-tag">\( f^{-1}\)</span><span class="math-tag">\begin{aligned}             & v = \lambda \cdot f^{-1}(v)             & \iff         \end{aligned}</span>         Moltiplicando da "entrambe le parti" per il reciproco di <span class="math-tag">\( \lambda\)</span> (che non è nullo, in quanto <span class="math-tag">\( f\)</span> non sarebbe invertibile)         si ha che         <span class="math-tag">\[             \frac{1}{\lambda} v = f^{-1}(v)             \qquad \implies \qquad             f^{-1}(v) = \frac{1}{\lambda} v          \]</span>         che dimostra la proposizione.     </div></div></div><div class="subsection part" id="subsec7-2" ><span class="subsection-header part-title">7.2 - Diagonalizzazione di una matrice</span><div class="definition environment" id="def7-6" ><span class="definition-header environment-title">Definizione 7.6 - Base spettrale</span>     Considerando un endomorfismo <span class="math-tag">\( f: V \to V\)</span>, ogni base di <span class="math-tag">\( V\)</span> composta solamente da autovettori di <span class="math-tag">\( f\)</span> si dice base spettrale. </div><div class="definition environment" id="def7-7" ><span class="definition-header environment-title">Definizione 7.7 - Endomorfismo semplice</span>     Un endomorfismo <span class="math-tag">\( f\)</span> che ammette almeno una base spettrale, si dice semplice.     <div class="mynote environment" ><span class="mynote-header environment-title">Osservazioni personali - Esempio di endomorfismo non semplice</span>         Un esempio di endomorfismo non semplice è la rotazione di <span class="math-tag">\( 90\degree\)</span> in senso orario nel piano (infatti solo il vettore nullo ha come immagine un multiplo di sè stesso).      </div></div><div class="definition environment" id="def7-8" ><span class="definition-header environment-title">Definizione 7.8 - Matrice associata ad un endomorfismo semplice rispetto alla base spettrale</span>     Considerando una base spettrale <span class="math-tag">\( B = (v_{1}, \ \ldots \ , v_{n})\)</span> per un endomorfismo <span class="math-tag">\( f\)</span>, allora la matrice associata all'endomorfismo <span class="math-tag">\( f\)</span> rispetto alla base <span class="math-tag">\( B\)</span> (<span class="math-tag">\( M_{B, B}(f)\)</span>) è diagonale. Su tale diagonale compaiono gli autovalori associati agli autovettori <span class="math-tag">\( (v_{1}, \ \ldots \ , v_{n})\)</span>.     <br ></br>     Viceversa, si può dire che se una matrice associata ad un endomorfismo rispetto ad una base è diagonale, allora tale base è spettrale.      <div class="mynote environment" ><span class="mynote-header environment-title">Osservazioni personali - Tell me why</span>         Ciò risulta evidente costruendo la matrice associata ad <span class="math-tag">\( f\)</span>. Infatti le colonne della matrice sono le coordinate dell'immagine di ogni vettore della base rispetto alla base <span class="math-tag">\( B\)</span>, ovvero:         <span class="math-tag">\begin{aligned}             & f(v_{1}) = \lambda_{1} \cdot v_{1} + 0 \cdot v_{2} + \ \ldots \ + 0 \cdot v_{n}              & \\             & f(v_{2}) = 0 \cdot v_{1} + \lambda_{2} \cdot v_{2} + \ \ldots \ + 0 \cdot v_{n}              & \\             & \vdots &              \\             & f(v_{n}) = 0 \cdot v_{1} + 0 \cdot v_{2} + \ \ldots \ + \lambda_{n} \cdot v_{n}              &         \end{aligned}</span>         che sarebbe         <span class="math-tag">\[             M_{B, B}(f) =             \left(             \begin{array}{cccc}                 \lambda_{1} & 0 & \cdots & 0 \\                 0 & \lambda_{2} & \cdots & 0 \\                 \vdots & \vdots & \ddots & \vdots \\                 0 & 0 & \cdots & \lambda_{n}             \end{array}             \right)         \]</span></div></div><div class="definition environment" id="def7-9" ><span class="definition-header environment-title">Definizione 7.9 - Molteplicità algebrica degli autovalori</span>     Considerando la matrice <span class="math-tag">\( A \in M_{n \times n}(\mathbb{K})\)</span> associata all'endomorfismo <span class="math-tag">\( f\)</span> e <span class="math-tag">\( \lambda_{1}, \ \ldots \ , \lambda_{s}\)</span> i suoi autovalori (con <span class="math-tag">\( s \leq n\)</span>), allora è possibile scrivere il polinomio caratteristico di <span class="math-tag">\( A\)</span> come     <span class="math-tag">\[         p_{A} = (\lambda - a_{1})^{k_{1}} \cdot (\lambda - a_{2})^{k^{2}} \cdot \ \ldots \ \cdot (\lambda - a_{s})^{k_{s}} \cdot q(\lambda)     \]</span>     dove <span class="math-tag">\( a_{1}, \ \ldots \ , a_{s}\)</span> sono le radici per cui si annulla il polinomio). Definiamo quindi <span class="math-tag">\( k_{i}\)</span> la molteplicità algebrica dell'autovalore <span class="math-tag">\( \lambda_{i}\)</span>, ovvero     <span class="math-tag">\[         ma(\lambda_{i}) = k_{i}     \]</span><div class="mynote environment" ><span class="mynote-header environment-title">Osservazioni personali - In poche parole</span>         La molteplicità algebrica si può definire anche come il numero di volte in cui l'autovalore <span class="math-tag">\( \lambda_{i}\)</span> annulla il polinomio caratteristico.     </div></div><div class="definition environment" id="def7-10" ><span class="definition-header environment-title">Definizione 7.10 - Molteplicità geometrica degli autovalori</span>     Considerando la matrice <span class="math-tag">\( A \in M_{n \times n}(\mathbb{K})\)</span> associata all'endomorfismo <span class="math-tag">\( f\)</span> e <span class="math-tag">\( \lambda_{1}, \ \ldots \ , \lambda_{s}\)</span> i suoi autovalori (con <span class="math-tag">\( s \leq n\)</span>), si definisce molteplicità geometrica di un autovalore <span class="math-tag">\( \lambda_{i}\)</span> la dimensione dell'autospazio a lui associato, ovvero     <span class="math-tag">\[         mg(\lambda_{i}) = dim(U_{\lambda_{i}})     \]</span>     Detto ciò, si ha che la molteplicità geometrica di un autovalore è uguale a <span class="math-tag">\( n\)</span> meno il rango della matrice caratteristica, ovvero     <span class="math-tag">\[         dim(U_{\lambda_{i}}) = mg(\lambda_{i}) = n - r(A - \lambda_{i}I)     \]</span></div><div class="definition environment" id="def7-11" ><span class="definition-header environment-title">Definizione 7.11 - Relazione molteplicità algebrica e geometrica degli autovalori</span>     Considerando <span class="math-tag">\( \lambda\)</span> un autovalore dell'endomorfismo <span class="math-tag">\( f\)</span>, si ha che     <span class="math-tag">\[         1 \leq mg(\lambda) \leq ma(\lambda)     \]</span><div class="mynote environment" ><span class="mynote-header environment-title">Osservazioni personali - </span>        Il fatto che la molteplicità geometrica di <span class="math-tag">\( \lambda\)</span> debba essere maggiore o uguale a <span class="math-tag">\( 1\)</span> è banale: infatti se la dimensione di <span class="math-tag">\( U_{\lambda}\)</span> fosse <span class="math-tag">\( 0\)</span> non si avrebbe un autospazio (in quanto ci sarebbe solo il vettore nullo).     </div></div><div class="demonstration environment" id="dem7-6" ><span class="demonstration-header environment-title">Dimostrazione 7.6 - Lineare indipendenza di vettori appartenenti a diversi autospazi</span>     Dato il lemma     <div class="proposition environment" ><span class="proposition-header environment-title">Enunciato</span>         Considerando un endomorfismo <span class="math-tag">\( f: V \to V\)</span> e i suoi autospazi <span class="math-tag">\( U_{\lambda_{1}}, \ \ldots \ , U_{\lambda_{k}}\)</span>, allora i vettori appartenenti agli autospazi sono linearmente indipendenti tra loro.     </div><div class="proof environment" ><span class="proof-header environment-title">Dimostrazione:</span>         Per dimostrare ciò, ipotizziamo per assurdo che la <span class="math-tag">\( k\)</span>-upla di vettori <span class="math-tag">\( (v_{1}, \ \ldots \ , v_{k})\)</span> provenienti da autospazi distinti  siano linearmente dipendenti. Possiamo quindi dire che esiste almeno una <span class="math-tag">\( k\)</span>-upla di coordinate non nulla <span class="math-tag">\( (\alpha_{1}, \ \ldots \ , \alpha_{k})\)</span> che soddisfa tale equazione         <span class="math-tag">\[             \alpha_{1} \cdot v_{1} + \ \ldots \ + \alpha_{k} \cdot v_{k} = 0         \]</span>         Tra una di queste <span class="math-tag">\( k\)</span>-uple non nulle, scegliamo la <span class="math-tag">\( k\)</span>-upla il cui numero di elementi non nulli è minimizzato, ovvero il numero di valori non nulli è il più piccolo possibile, ma non è <span class="math-tag">\( 0\)</span> (ovvero non si deve considerare la <span class="math-tag">\( k\)</span>-upla nulla). Chiamiamo tale <span class="math-tag">\( k\)</span>-upla <span class="math-tag">\( (\bar{\alpha}_{1}, \ \ldots \ , \bar{\alpha}_{k})\)</span>.         <br ></br>         Riprendendo la relazione enunciata in precedenza, è lecito scrivere         <span class="math-tag">\begin{aligned}             & \bar{\alpha}_{1} \cdot v_{1} +  \ \ldots \ + \bar{\alpha}_{k} \cdot v_{k} = 0             & \iff         \end{aligned}</span>         Applicando a ciò quindi l'endomorfismo <span class="math-tag">\( f\)</span><span class="math-tag">\begin{aligned}             & f(\bar{\alpha}_{1} \cdot v_{1} +  \ \ldots \ + \bar{\alpha}_{k} \cdot v_{k}) = f(0)             & \iff         \end{aligned}</span>         è possibile utilizzare la linearità per ottenere         <span class="math-tag">\begin{aligned}             & \bar{\alpha}_{1} \cdot f(v_{1}) +  \ \ldots \ +  \bar{\alpha}_{k} \cdot f(v_{k}) = 0             & \iff         \end{aligned}</span>         Ora, scrivendo l'immagine dei vettori si ottiene         <span class="math-tag">\begin{aligned}             & \bar{\alpha}_{1} \cdot \lambda_{1} \cdot v_{1} +  \ \ldots \ +  \bar{\alpha}_{k} \cdot \lambda_{k} \cdot v_{k} = 0             & \iff         \end{aligned}</span>         Ora, ritornando all'uguaglianza          <span class="math-tag">\begin{aligned}             & \bar{\alpha}_{1} \cdot v_{1} +  \ \ldots \ + \bar{\alpha}_{k} \cdot v_{k} = 0             & \iff         \end{aligned}</span>         invece di applicare l'endomorfismo, consideriamo che <span class="math-tag">\( \lambda_{1} \neq 0\)</span> (o un qualsiasi altro autovalore non nullo) e moltiplichiamolo all'equazione da "entrambe le parti", ovvero         <span class="math-tag">\begin{aligned}             & \bar{\alpha}_{1} \cdot \lambda_{1} \cdot v_{1} +  \ \ldots \ + \bar{\alpha}_{k} \cdot \lambda_{1} \cdot v_{k} = 0             & \iff         \end{aligned}</span>         Ora, ricordando che stiamo lavorando con delle uguaglianze, è lecito scrivere         <span class="math-tag">\begin{aligned}             & \bar{\alpha}_{1} \cdot \lambda_{1} \cdot v_{1} +  \ \ldots \ +  \bar{\alpha}_{k} \cdot \lambda_{k} \cdot v_{k} = \bar{\alpha}_{1} \cdot \lambda_{1} \cdot v_{1} +  \ \ldots \ + \bar{\alpha}_{k} \cdot \lambda_{1} \cdot v_{k}             & \iff         \end{aligned}</span>         Aggiungendo da entrambe le parti l'opposto del termine di destra, si ottiene         <span class="math-tag">\begin{aligned}             & \bar{\alpha}_{2} \cdot \lambda_{2} \cdot v_{2} +  \ \ldots \ +  \bar{\alpha}_{k} \cdot \lambda_{k} \cdot v_{k} - \bar{\alpha}_{2} \cdot \lambda_{1} \cdot v_{2} -  \ \ldots \ - \bar{\alpha}_{k} \cdot \lambda_{1} \cdot v_{k} = 0             & \iff         \end{aligned}</span>         Facendo notare che il termine <span class="math-tag">\( \bar{\alpha}_{1} \cdot \lambda_{1} \cdot v_{1}\)</span> si è annullato, possiamo raccogliere i coefficienti <span class="math-tag">\( \bar{\alpha}_{i}\)</span> e scrivere         <span class="math-tag">\begin{aligned}            & \bar{\alpha}_{2} \cdot (\lambda_{2} - \lambda_{1}) \cdot v_{2} + \ \ldots \ + \bar{\alpha}_{k} \cdot (\lambda_{k} - \lambda{1}) \cdot v_{2} = 0            &         \end{aligned}</span>         Dato che tutti i valori <span class="math-tag">\( \lambda\)</span> sono distinti (in quanto provenienti da autospazi differenti), allora si ha che le differenze <span class="math-tag">\( (\lambda_{i} - \lambda_{1})\)</span> non saranno mai nulle. Abbiamo quindi raggiunto un assurdo, in quanto avremmo trovato una <span class="math-tag">\( k\)</span>-upla in cui il numero di elementi non nulli è minore della <span class="math-tag">\( k\)</span>-upla <span class="math-tag">\( (\bar{\alpha}_{1}, \ \ldots \ , \bar{\alpha}_{k})\)</span> in quanto <span class="math-tag">\( \bar{\alpha}_{1}\)</span> è ora nullo.          <br ></br>         Si è dimostrata quindi la proposizione.     </div></div><div class="demonstration environment" id="dem7-7" ><span class="demonstration-header environment-title">Dimostrazione 7.7 - Condizione necessaria e sufficiente che garantisce la semplicità di un endomorfismo</span>     Dato il teorema     <div class="proposition environment" ><span class="proposition-header environment-title">Enunciato</span>         Un endomorfismo <span class="math-tag">\( f: V \to V\)</span>, (con <span class="math-tag">\( dim(V) = n\)</span>) è semplice se e solo se la somma delle dimensioni di tutti i suoi autospazi è uguale a <span class="math-tag">\( n\)</span>, ovvero         <span class="math-tag">\[             \sum dim(U_{\lambda_{i}}) = n         \]</span></div><div class="mynote environment" ><span class="mynote-header environment-title">Osservazioni personali - In altre parole</span>         Dire che la somma delle dimensioni degli autospazi deve essere <span class="math-tag">\( n\)</span> è equivalente a dire che la somma delle molteplicità geometriche degli autovalori deve essere <span class="math-tag">\( n\)</span>, ovvero         <span class="math-tag">\[             \sum mg(\lambda_{i}) = n         \]</span></div><div class="proof environment" ><span class="proof-header environment-title">Dimostrazione:</span>         Per dimostrare tale teorema è necessario dimostrare che         <ul ><li >"se la somma delle dimensioni di tutti gli autospazi di un endomorfismo <span class="math-tag">\( f\)</span> è <span class="math-tag">\( n\)</span>, allora <span class="math-tag">\( f\)</span> è semplice".              <br ></br>             Per dimostrarlo è necessario provare che esiste una base spettrale per <span class="math-tag">\( f\)</span>. Consideriamo quindi di costruirla unendo le basi degli autospazi:             <span class="math-tag">\begin{aligned}                 & B_{U_{\lambda_{1}}} = (v_{1}^{1}, \ \ldots \ , v_{r_{1}}^{1}) \\                 & B_{U_{\lambda_{2}}} = (v_{1}^{2}, \ \ldots \ , v_{r_{2}}^{2}) \\                 & \vdots \\                 & B_{U_{\lambda_{k}}} = (v_{1}^{k}, \ \ldots \ , v_{r_{k}}^{k})             \end{aligned}</span>             dove l'apice indica l'autospazio di appartenenza, ed il pedice la posizione del vettore in ogni base (<span class="math-tag">\( r_{k}\)</span> indica la dimensione dell'autospazio). Otteniamo quindi una base <span class="math-tag">\( B_{V}\)</span> per <span class="math-tag">\( V\)</span> contenente <span class="math-tag">\( n\)</span> vettori. Per provare che sia una base, è sufficiente provare la lineare indipendenza, ovvero che tutti i coefficienti possono essere solo nulli.             <span class="math-tag">\begin{aligned}                 &                 \begin{array}{lclc}                     0 & = &                      \alpha_{1}^{1} \cdot v_{1}^{1} + \ \ldots \ + \alpha_{r_{1}}^{1} \cdot v_{r_{1}}^{1} & + \\                     & + & \alpha_{1}^{2} \cdot v_{1}^{2} + \ \ldots \ + \alpha_{r_{1}}^{2} \cdot v_{r_{2}}^{2}                      & + \\                     & + & \ldots & + \\                     & + & \alpha_{1}^{k} \cdot v_{1}^{k} + \ \ldots \ + \alpha_{r_{k}}^{k} \cdot v_{r_{k}}^{k} &                 \end{array}                 & \iff             \end{aligned}</span>             Dato che ogni riga è combinazione lineare di un distinto autospazio, è possibile sostituirla con un vettore qualsiasi appartenente a quell'autospazio, ovvero             <span class="math-tag">\begin{aligned}                 & 0 = v^{1} + v^{2} + \ \ldots \ + v^{k}                 & \iff             \end{aligned}</span>             Sappiamo tuttavia che, per il lemma sulla "lineare indipendenza di vettori appartenenti a diversi autospazi", che tali vettori sono linearmente indipendenti tra loro. Abbiamo quindi la combinazione lineare del vettore nullo di vettori linearmente indipendenti tra loro: tali vettori devono quindi essere tutti nulli. Se ogni vettore <span class="math-tag">\( v^{i}\)</span> è nullo, otteniamo             <span class="math-tag">\begin{aligned}                 & 0 = \alpha_{1}^{i} \cdot v_{1}^{i} + \ \ldots \ + \alpha_{r_{1}}^{i} \cdot v_{r_{1}}^{i}                 &              \end{aligned}</span>             ovvero la combinazione lineare del vettore nullo di vettori linearmente indipendenti: ogni coordinata deve essere quindi nulla. Dato che si è verificata la lineare indipendenza, si è dimostrata l'implicazione.             </li><li >"se un endomorfismo <span class="math-tag">\( f\)</span> è semplice, allora la somma delle dimensioni di tutti i suoi autospazi è <span class="math-tag">\( n\)</span>".              <br ></br>             Per dimostrare ciò consideriamo che <span class="math-tag">\( f\)</span> semplice implica l'esistenza di una base <span class="math-tag">\( B_{V}\)</span> per <span class="math-tag">\( V\)</span> composta da <span class="math-tag">\( n\)</span> autovettori: esistono quindi almeno <span class="math-tag">\( n\)</span> autovettori linearmente indipendenti tra loro. Inoltre sappiamo che non possono esistere più di <span class="math-tag">\( n\)</span> autovettori linearmente indipendenti, in quanto il massimo numero di vettori linearmente indipendenti è proprio <span class="math-tag">\( n\)</span> (altrimenti due basi avrebbero dimensione diversa). Si ha quindi che la somma delle dimensioni di autospazi è proprio <span class="math-tag">\( n\)</span>. Si è quindi dimostrata l'implicazione.         </li></ul>         Si è quindi verificato il teorema.     </div></div><div class="myexample environment" id="example41" ><span class="myexample-header environment-title">Esempio 41 - Diagonalizzazione di una matrice</span>     Dire se la matrice      <span class="math-tag">\[         A =          \left(         \begin{array}{ccc}             3 & 0 & 0 \\             -4 & -1 & -8 \\             0 & 0 & 3         \end{array}         \right)     \]</span>     è diagonalizzabile. Se lo è, calcolare una base spettrale e la relativa forma diagonale di <span class="math-tag">\( A\)</span>.     <br ></br>     Innanzitutto, calcoliamo il polinomio caratteristico di <span class="math-tag">\( A\)</span>, ovvero     <span class="math-tag">\[         p_{A}(\lambda) = det         \left(         \begin{array}{ccc}             3 - \lambda & 0 & 0 \\             -4 & -1 - \lambda & -8 \\             0 & 0 & 3 - \lambda         \end{array}         \right)         =          (\lambda - 3)^{2} \cdot (\lambda + 1)     \]</span>     da cui otteniamo gli autovalori <span class="math-tag">\( 3\)</span> e <span class="math-tag">\( -1\)</span>.     <br ></br>     &Egrave; banale ottenere la molteplicità geometrica dell'autovalore <span class="math-tag">\( -1\)</span>: infatti abbiamo che la sua molteplicità algebrica è <span class="math-tag">\( 1\)</span> e per la relazione <span class="math-tag">\( 1 \leq mg(-1) \leq ma(-1)\)</span> è semplice ottenere che la sua molteplicità geometrica è <span class="math-tag">\( 1\)</span>.     <br ></br>     Per quanto riguarda l'autovalore <span class="math-tag">\( 3\)</span>, è più complicato in quanto è necessario calcolare la dimensione dell'autospazio <span class="math-tag">\( U_{3}\)</span>, ovvero sostituendo alla matrice caratteristica <span class="math-tag">\( \lambda = 3\)</span>, si ottiene     <span class="math-tag">\[         \left(         \begin{array}{ccc}             0 & 0 & 0 \\             4 & 4 & 8 \\             0 & 0 & 0         \end{array}         \right)     \]</span>     e considerandola come un sistema lineare     <span class="math-tag">\[         \left\{          \begin{array}{ccccccc}              4x & + & 4y & + & 8z & = & 0 \\         \end{array}         \right.     \]</span>     e risolvendolo in forma parametrica si ottiene      <span class="math-tag">\[         \left\{          \begin{array}{ccl}              x & = & -s - 2t \\              y & = & s  \\              z & = & t          \end{array}         \right.         \qquad         \implies         \qquad         \left(         \begin{array}{c}             x \\             y \\             z         \end{array}         \right)         =         s \cdot          \left(         \begin{array}{c}             -1 \\             1 \\             0         \end{array}         \right)         +          t \cdot          \left(         \begin{array}{c}             -2 \\             0 \\             1         \end{array}         \right)     \]</span>     Abbiamo quindi ottenuto che la dimensione di <span class="math-tag">\( U_{3}\)</span> è <span class="math-tag">\( 2\)</span> e gli autovettori associati sono <span class="math-tag">\( ((-1, 1, 0), (-2, 0, 1))\)</span>. Ora sappiamo che la matrice è diagonalizzabile in quanto      <span class="math-tag">\[         mg(-1) + mg(3) = 1 + 2 = n     \]</span>     Per ottenere una base spettrale è sufficiente calcolare un autovettore per l'autovalore <span class="math-tag">\( \lambda = -1\)</span>. Per farlo utilizziamo quindi lo stesso procedimento di prima, ovvero     <span class="math-tag">\[         \left(         \begin{array}{ccc}             -4 & 0 & 0 \\             4 & 0 & 8 \\             0 & 0 & -4         \end{array}         \right)     \]</span>     e considerandola come un sistema lineare     <span class="math-tag">\[         \left\{          \begin{array}{ccccccc}             -4x & + & 0  & + & 0 & = & 0 \\              4x & + & 0 & + & 8z & = & 0 \\              0 & + & 0 & - & 4z & = & 0         \end{array}         \right.     \]</span>     e risolvendolo in forma parametrica si ottiene      <span class="math-tag">\[         \left\{          \begin{array}{ccl}              x & = & 0 \\              y & = & s  \\              z & = & 0          \end{array}         \right.         \qquad         \implies         \qquad         \left(         \begin{array}{c}             x \\             y \\             z         \end{array}         \right)         =         s \cdot          \left(         \begin{array}{c}             0 \\             1 \\             0         \end{array}         \right)     \]</span>     da cui si ottiene che l'autovettore associato all'autovalore <span class="math-tag">\( -1\)</span> è <span class="math-tag">\( (0, 1, 0)\)</span>.     <br ></br>     In conclusione, data la base spettrale <span class="math-tag">\( ((-1, 1, 0), (-2, 0, 1), (0, 1, 0))\)</span> otterremo la matrice diagonale     <span class="math-tag">\[         \left(         \begin{array}{ccc}             3 & 0 & 0 \\             0 & 3 & 0 \\             0 & 0 & -1         \end{array}         \right)     \]</span></div><div class="definition environment" id="def7-12" ><span class="definition-header environment-title">Definizione 7.12 - Esistenza di almeno un autovalore per ogni endomorfismo di dimensione dispari</span>     Considerando un endomorfismo <span class="math-tag">\( f: V \to V\)</span> dove <span class="math-tag">\( dim(V) = n\)</span>, se <span class="math-tag">\( n\)</span> è dispari si ha sempre almeno un autovalore, in quanto il grado del polinomio caratteristico è dispari. </div><div class="demonstration environment" id="dem7-8" ><span class="demonstration-header environment-title">Dimostrazione 7.8 - Diagonalizzabilità di una matrice data l'esistenza di <span class="math-tag">\( n\)</span> autovalori distinti</span>     Data la proposizione     <div class="proposition environment" ><span class="proposition-header environment-title">Enunciato</span>         Se una matrice <span class="math-tag">\( A \in M_{n \times n}(\mathbb{R})\)</span> associata ad un endomorfismo <span class="math-tag">\( f\)</span> ha <span class="math-tag">\( n\)</span> autovalori distinti, allora è diagonalizzabile.      </div><div class="mynote environment" ><span class="mynote-header environment-title">Osservazioni personali - In altre parole</span>         Ciò è equivalente a dire che un endomorfismo <span class="math-tag">\( f: V \to V\)</span>  che ammette <span class="math-tag">\( n\)</span> (ovvero un numero pari alla dimensione di <span class="math-tag">\( V\)</span>) autovalori distinti è semplice.     </div><div class="proof environment" ><span class="proof-header environment-title">Dimostrazione:</span>         Per dimostrare ciò consideriamo che la molteplicità geometrica di ogni autovalore non può essere inferiore a <span class="math-tag">\( 1\)</span>: nel caso avessimo <span class="math-tag">\( n\)</span> autovalori distinti otterremo che la somma delle dimensioni degli autospazi è almeno pari a <span class="math-tag">\( n\)</span> e, dato che sono linearmente indipendenti, si ha che non possono essere più di <span class="math-tag">\( n\)</span> (altrimenti sarebbero una base con una dimensione diversa da altre basi). Otteniamo quindi che la somma delle dimensioni è esattamente <span class="math-tag">\( n\)</span>, implicando quindi l'esistenza di una base spettrale (e la semplicità dell'endomorfismo).     </div></div><div class="myexample environment" id="example42" ><span class="myexample-header environment-title">Esempio 42 - Utilizzo della diagonalizzabilità di una matrice data l'esistenza di <span class="math-tag">\( n\)</span> autovalori distinti</span>     Data la matrice     <span class="math-tag">\[         A =         \begin{pmatrix}            1 & 7 & 4 \\            0 & 3 & -10 \\            0 & 0 & 8         \end{pmatrix}     \]</span>     dire se esiste una base spettrale.     <br ></br>     Per farlo si è sufficiente calcolare il polinomio caratteristico di <span class="math-tag">\( A\)</span>, ovvero     <span class="math-tag">\begin{aligned}         p_{A}(\lambda) = det(A - \lambda I) = det         \left(         \begin{array}{ccc}             1 - \lambda & 7 & 4 \\             0 & 3 - \lambda & -10 \\             0 & 0 & 8 - \lambda         \end{array}         \right)         = (1 - \lambda) \cdot (3 - \lambda) \cdot (8 - \lambda)     \end{aligned}</span>     ovvero ammette <span class="math-tag">\( 3\)</span> autovalori distinti: ciò implica l'esistenza di una base spettrale. </div><div class="definition environment" id="def7-13" ><span class="definition-header environment-title">Definizione 7.13 - Teorema - Diagonalizzabilità di ogni matrice simmetrica</span>     Considerando una matrice simmetrica, essa è diagonalizzabile. </div><div class="myexample environment" id="example43" ><span class="myexample-header environment-title">Esempio 43 - Diagonalizzabilità di una matrice contenente parametri</span>     Dato il seguente endomorfismo     <span class="math-tag">\begin{aligned}         & f: \mathbb{R}^{3} \to \mathbb{R}^{3}          & f(x, y, z) = (kx + 2y - z, x + ky - z, 2z)      \end{aligned}</span>     dire per quali valori di <span class="math-tag">\( k\)</span>, l'endomorfismo <span class="math-tag">\( f\)</span> è semplice.     <br ></br>     Per rispondere a tale domanda, innanzitutto scriviamo la matrice associata <span class="math-tag">\( A\)</span>,     <span class="math-tag">\[         A =          \left(         \begin{array}{ccc}             k & 2 & -1 \\             1 & k & -1 \\             0 & 0 & 2         \end{array}         \right)     \]</span>     e calcoliamo il polinomio caratteristico     <span class="math-tag">\[         p_{A}(\lambda) = det         \left(         \begin{array}{ccc}             k - \lambda & 2 & -1 \\             1 & k - \lambda & -1 \\             0 & 0 & 2 - \lambda         \end{array}         \right)         = (2 - \lambda) \cdot [(k - \lambda)^{2} - 2]     \]</span>     gli autovalori sono quindi <span class="math-tag">\( 2\)</span>, <span class="math-tag">\( k - \sqrt{2}\)</span> e <span class="math-tag">\( k + \sqrt{2}\)</span>.      <br ></br>     Tali valori sono distinti per la maggior parte dei valori di <span class="math-tag">\( k\)</span>: gli unici casi che non rientrano in ciò sono:     <ul ><li >quando <span class="math-tag">\( 2\)</span> e <span class="math-tag">\( k - \sqrt{2}\)</span> coincidono, ovvero <span class="math-tag">\( k = 2 + \sqrt{2}\)</span>;         </li><li >quando <span class="math-tag">\( 2\)</span> e <span class="math-tag">\( k + \sqrt{2}\)</span> coincidono, ovvero <span class="math-tag">\( k = 2 - \sqrt{2}\)</span>;         </li><li >quando <span class="math-tag">\( k - \sqrt{2}\)</span> e <span class="math-tag">\( k + \sqrt{2}\)</span> coincidono, ovvero mai.     </li></ul>     Ora, è sufficiente proseguire l'esercizio solo per <span class="math-tag">\( k = 2 + \sqrt{2}\)</span> e <span class="math-tag">\( k = 2 - \sqrt{2}\)</span>.     <br ></br>     Quindi, considerando <span class="math-tag">\( k = 2 \pm \sqrt{2}\)</span> abbiamo la matrice caratteristica uguale a         <span class="math-tag">\[             A =              \left(             \begin{array}{ccc}                 (2 \pm \sqrt{2}) - \lambda & 2 & -1 \\                 1 & (2 \pm \sqrt{2}) - \lambda & -1 \\                 0 & 0 & 2 - \lambda             \end{array}             \right)         \]</span>         e il polinomio caratteristico è pari a <span class="math-tag">\( p_{A}(\lambda) = (2 - \lambda) \cdot ((2 \pm \sqrt{2}) - \lambda)^{2}\)</span>. &Egrave; quindi sufficiente calcolare la molteplicità geometrica di <span class="math-tag">\( (2 \pm \sqrt{2})\)</span> in quanto la molteplicità geometrica di <span class="math-tag">\( 2\)</span> è <span class="math-tag">\( 1\)</span>. Quindi, calcolando <span class="math-tag">\( U_{2 \pm \lambda}\)</span>, scriviamo il sistema lineare sostituendo a <span class="math-tag">\( \lambda\)</span> rispettivamente <span class="math-tag">\( (2 \pm \sqrt{2})\)</span>:         <span class="math-tag">\[             \left\{                 \begin{array}{ccccccc}                      0 & + & 2y & - & z & = & 0 \\                      x & + & 0 & - & z & = & 0 \\                      0 & + & 2y & \mp & (\sqrt{2}) z & = & 0 \\                 \end{array}             \right.         \]</span>         da cui otteniamo un sistema la cui soluzione è unica (ovvero <span class="math-tag">\( mg(2 \pm \lambda) = 0\)</span>), per cui per questi valori la matrice non è diagonalizzabile. </div></div></div>
    </div>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>