<!DOCTYPE html>
<html lang="IT">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="stylesheet" href="../styles/style.css" />
    <link rel="stylesheet" href="../styles/index-style.css" />
    <link rel="stylesheet" href="../styles/content-style.css" />
    <link rel="icon" type="image/x-icon" href="../resources/favicon.ico">
    <link rel="apple-touch-icon" href="../resources/favicon.png" />
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-78NHLXDQD8"></script>
    <script src="../scripts/script.js"></script>
    <style>:root { --bg-clr: #296a15; --fg-clr: #e8e3e3; }</style>
    <meta name="theme-color" content="#296a15" />
    <meta name="keywords" content="geometria, algebra, geometria e algebra, algebra lineare, GAL" />
    <meta name="description" content="Il seguente sito contiene gli appunti, le definizioni e le dimostrazioni spiegate del corso 'Geometria e algebra'.">
    <meta name="robots" content="index">
    <script defer async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <title>Geometria e algebra - Spazi vettoriali euclidei - Spazi vettoriali euclidei</title>
</head>
<body>
    <div class="container">
        <header class="header-wrapper">
            <div class="title-wrapper">
                <span class="title">
                    Geometria e algebra
                </span>
                <span class="subtitle">
                    by lorenzoarlo
                </span>
            </div>
            <span class="page-title">
                Spazi vettoriali euclidei
            </span>
        </header>
        <section class="content-wrapper">
            <h1 class="section-title content-width">Spazi vettoriali euclidei</h1>
            <article class="content-container content-width">
                <div class="definition environment" id="def8-4"><h2 class="environment-title">Definizione - Spazio vettoriale euclideo</h2><div class="environment-body">     Uno spazio vettoriale <span class="math-span">\( (\mathbb{K}, V, +, \cdot)\)</span> si definisce euclideo se è dotato di un prodotto scalare.     <div class="mynote environment"><h3 class="environment-title">Osservazioni personali - Esempio di spazio vettoriale euclideo</h3><div class="environment-body">         Un esempio di spazi vettoriale euclideo è <span class="math-span">\( \mathbb{R}^{n}\)</span> (<span class="math-span">\( (\mathbb{R}, \mathbb{R}^{2}, +, \cdot)\)</span>) con un qualsiasi prodotto scalare valido.     </div></div></div></div><div class="definition environment" id="def8-5"><h2 class="environment-title">Definizione - Norma di un vettore</h2><div class="environment-body">     Considerando uno spazio vettoriale euclideo, si definisce come norma di un vettore <span class="math-span">\( v\)</span> appartenente allo spazio vettoriale, il prodotto scalare tra il vettore e se stesso, ovvero lo scalare     <span class="math-block">\[         ||v|| = \sqrt{v \star v}     \]</span><div class="mynote environment"><h3 class="environment-title">Osservazioni personali - Versori</h3><div class="environment-body">         I vettori di norma <span class="math-span">\( 1\)</span> sono detti versori.     </div></div></div></div><div class="myexample environment" id="example45"><h2 class="environment-title">Esempio - Esempio di calcolo della norma nel caso del prodotto scalare standard</h2><div class="environment-body">     Considerando lo spazio vettoriale euclideo <span class="math-span">\( (\mathbb{R}^{2}, \star)\)</span>, dove <span class="math-span">\( \star\)</span> è il prodotto scalare standard, allora la norma di un vettore <span class="math-span">\( v = (1, 1)\)</span> sarà     <span class="math-block">\[         ||v|| = \sqrt{1^{2} + 1^{2}}  = \sqrt{2}      \]</span>     che è equivalente al calcolo del modulo di un vettore tramite il teorema di pitagora. </div></div><div class="myexample environment" id="example46"><h2 class="environment-title">Esempio - Esempio del calcolo della norma nel caso di un prodotto scalare qualsiasi</h2><div class="environment-body">     Considerando lo spazio vettoriale euclideo <span class="math-span">\( (\mathbb{R}^{2}, \star)\)</span>, dove <span class="math-span">\( \star\)</span> è il prodotto scalare associato alla seguente matrice     <span class="math-block">\[         \left(         \begin{array}{cc}             2 &amp; 1 \\             1 &amp; 1         \end{array}         \right)     \]</span>     allora la norma di un vettore <span class="math-span">\( v = (1, 1)\)</span> sarà     <span class="math-block">\[         ||v|| =         \sqrt         {             \left(             \begin{array}{cc}                 1 &amp; 1             \end{array}             \right)             \odot             \left(             \begin{array}{cc}                 2 &amp; 1 \\                 1 &amp; 1             \end{array}             \right)             \odot              \left(             \begin{array}{c}                 1 \\                 1             \end{array}              \right)         }         =         \sqrt{5}     \]</span></div></div><div class="definition environment" id="def8-6"><h2 class="environment-title">Definizione - Angolo tra due vettori</h2><div class="environment-body">     In un spazio vettoriale euclideo, si definisce angolo <span class="math-span">\( \widehat{vw}\)</span> tra due vettori <span class="math-span">\( v, w\)</span> dello spazio vettoriale, l'arcocoseno del valore ottenuto dal prodotto scalare tra i due vettori diviso il prodotto delle norme, ovvero     <span class="math-block">\[         \cos(\widehat{vw}) = \frac{v \star w}{||v|| \cdot ||w|| }     \]</span></div></div><div class="myexample environment" id="example47"><h2 class="environment-title">Esempio - Esempio di calcolo dell'angolo tra due vettori nel caso del prodotto scalare standard</h2><div class="environment-body">     Considerando lo spazio vettoriale euclideo <span class="math-span">\( (\mathbb{R}^{2}, \star)\)</span>, dove <span class="math-span">\( \star\)</span> è il prodotto scalare standard, allora l'angolo tra due vettori <span class="math-span">\( v = (1, 0)\)</span> e <span class="math-span">\( w = (1, 1)\)</span> sarà     <span class="math-block">\[         \cos(\widehat{vw}) = \frac{(1, 0) \star (1, 1)}{||(1, 0)|| \cdot ||(1, 1)||} = \frac{2}{2\sqrt{2}} = \frac{\sqrt{2}}{2}     \]</span>     ovvero l'angolo <span class="math-span">\( \frac{\pi}{4}\)</span>. </div></div><div class="definition environment" id="def8-7"><h2 class="environment-title">Definizione - Norma di un vettore sempre maggiore o uguale a <span class="math-span">\( 0\)</span></h2><div class="environment-body">     La norma di un vettore è sempre maggiore o uguale a <span class="math-span">\( 0\)</span>, proprio per la proprietà del prodotto scalare di essere definito positivo, ovvero     <span class="math-block">\[         ||v|| \geq 0     \]</span></div></div><div class="demonstration environment" id="dem8-2"><h2 class="environment-title">Dimostrazione - Norma del multiplo di un vettore</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato</h3><div class="environment-body">         La norma del multiplo di un vettore <span class="math-span">\( v\)</span> (<span class="math-span">\( \alpha \cdot v\)</span>), è il valore assoluto di <span class="math-span">\( \alpha\)</span> moltiplicata per la norma di <span class="math-span">\( v\)</span>, ovvero         <span class="math-block">\[             ||\alpha \cdot v|| = \left| \alpha \right| \cdot ||v||         \]</span></div></div><div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostrare tale proposizione, consideriamo la definizione di norma, ovvero         <span class="math-block">\begin{aligned}             &amp; ||\alpha \cdot v|| = \sqrt{(\alpha \cdot v) \star (\alpha \cdot v)}             &amp; \iff         \end{aligned}</span>         e per la bilinearità del prodotto scalare si può scrivere         <span class="math-block">\begin{aligned}             &amp; \sqrt{\alpha^{2} \cdot (v \star v)}             &amp; \iff \\             &amp; \left| \alpha \right| \cdot \sqrt{v \star v}              &amp; \iff \\             &amp; \left| \alpha \right| \cdot ||v||             &amp;         \end{aligned}</span>         Che dimostra la proposizione.     </div></div></div></div><div class="demonstration environment" id="dem8-3"><h2 class="environment-title">Dimostrazione - Quadrato della norma della somma di due vettori</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato</h3><div class="environment-body">         Considerando due vettori <span class="math-span">\( v, w\)</span>, il quadrato della norma del vettore somma <span class="math-span">\( v + w\)</span> è          <span class="math-block">\[             ||v + w||^{2} = ||v||^{2} + 2 \cdot (v \star w) + ||w||^{2}         \]</span></div></div><div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Considerando il quadrato della norma del vettore somma <span class="math-span">\( v + w\)</span>, si ha che         <span class="math-block">\begin{aligned}             &amp; ||v + w||^{2} = (v + w) \star (v + w)             &amp; \iff         \end{aligned}</span>         e per linearità si ha che         <span class="math-block">\begin{aligned}             &amp; (v \star v) + (v \star w) + (w \star v) + (w \star w)             &amp; \iff \\             &amp; ||v||^{2} + 2 \cdot (v \star w) + ||w||^{2}             &amp;         \end{aligned}</span>         che dimostra la proposizione.     </div></div></div></div><div class="demonstration environment" id="dem8-4"><h2 class="environment-title">Dimostrazione - Disuguaglianza di Cauchy-Schwarz</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato</h3><div class="environment-body">         Il valore assoluto del prodotto scalare di due vettori <span class="math-span">\( v, w\)</span> è minore o uguale al prodotto tra le due norme, ovvero         <span class="math-block">\[             \left| v \star w \right| \leq ||v|| \cdot ||w||         \]</span></div></div><div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostrare tale disuguaglianza, consideriamo la norma elevata al quadrato del vettore somma <span class="math-span">\( v + tw\)</span> (dove <span class="math-span">\( t\)</span> è una qualsiasi variabile reale) che per definizione è         <span class="math-block">\begin{aligned}             &amp; ||v + tw||^{2} = (v + tw) \star (v + tw)             &amp; \iff         \end{aligned}</span>         Per la bilinearità si può scrivere         <span class="math-block">\begin{aligned}             &amp; v \star v + t \cdot (v \star w) + t \cdot (v \star w) + t^{2} \cdot (w \star w)             &amp; \iff \\             &amp; t^{2} \cdot (w \star w) + 2t \cdot (v \star w) + (v \star v)             &amp; \iff \\             &amp; t^{2} \cdot ||w||^{2} + 2t \cdot (v \star w) + ||v||^{2}             &amp; \iff         \end{aligned}</span>         che possiamo vedere come un polinomio di secondo grado nella variabile <span class="math-span">\( t\)</span>. Dato che siamo partiti dalla norma <span class="math-span">\( ||v + tw||^{2}\)</span>, un valore sempre positivo o nullo         <span class="math-block">\[             t^{2} \cdot ||w||^{2} + 2t \cdot (v \star w) + ||v||^{2} \geq 0         \]</span>         possiamo dire che il discriminante di tale polinomio è minore o uguale a <span class="math-span">\( 0\)</span> (infatti si avrebbe una parabola che può essere solo tangente all'asse delle ascisse, ma mai secante dato che avrebbe una zona in cui è minore di <span class="math-span">\( 0\)</span>), ovvero         <span class="math-block">\begin{aligned}             &amp; (2 \cdot (v \star w))^{2} - 4 \cdot ||w||^{2} \cdot ||v||^{2}) \leq 0             &amp; \iff         \end{aligned}</span>         e risolvendo la disequazione         <span class="math-block">\begin{aligned}             &amp; 4 \cdot (v \star w)^{2} \leq 4 \cdot ||w||^{2} \cdot ||v||^{2}             &amp; \iff \\         \end{aligned}</span>         e eliminando l'esponente con la radice da entrambe le parti         <span class="math-block">\begin{aligned}             &amp; \left| v \star w \right| \leq ||v|| \cdot ||w||              &amp;         \end{aligned}</span>         si dimostra la proposizione.     </div></div></div></div><div class="definition environment" id="def8-8"><h2 class="environment-title">Definizione - Vettori ortogonali</h2><div class="environment-body">     Due vettori si definiscono ortogonali tra loro se e solo se il loro prodotto scalare è nullo, ovvero     <span class="math-block">\[         v \star w = 0         \qquad \iff \qquad         \text{$v$ e $w$ sono ortogonali}     \]</span></div></div><div class="definition environment" id="def8-9"><h2 class="environment-title">Definizione - Base ortogonale</h2><div class="environment-body">     Una base (in uno spazio vettoriale euclideo) si definisce ortogonale se i suoi vettori sono a due a due ortgonali tra loro.     <div class="mynote environment"><h3 class="environment-title">Osservazioni personali - Esempio di base ortogonale</h3><div class="environment-body">         Un esempio di base ortogonale per <span class="math-span">\( \mathbb{R}^{2}\)</span> considerando il prodotto scalare standard, è formata da un vettore ed uno dei due vettori perpendicolari ad esso.     </div></div></div></div><div class="definition environment" id="def8-10"><h2 class="environment-title">Definizione - Base ortonormale</h2><div class="environment-body">     Considerando una base ortogonale, se i suoi vettori sono tutti di norma <span class="math-span">\( 1\)</span>, essa si definisce una base ortonormale.     <div class="mynote environment"><h3 class="environment-title">Osservazioni personali - Esempio di base ortonormale</h3><div class="environment-body">         Un esempio di base ortonormale per <span class="math-span">\( \mathbb{R}^{n}\)</span> considerando il prodotto scalare standard, è la matrice identica.     </div></div></div></div><div class="demonstration environment" id="dem8-5"><h2 class="environment-title">Dimostrazione - Coordinate di un vettore rispetto ad una base ortonormale</h2><div class="environment-body">     Dato il teorema     <div class="proposition environment"><h3 class="environment-title">Enunciato</h3><div class="environment-body">         Considerando <span class="math-span">\( B = (v_{1}, \ \ldots \ , v_{n})\)</span> una base ortonormale, per ottenere la <span class="math-span">\( i\)</span>-esima coordinata di un qualsiasi vettore <span class="math-span">\( v\)</span> rispetto a tale base         <span class="math-block">\[             v = x_{1} \cdot v_{1} + \ \ldots \ + x_{i} \cdot v_{i}  + \ \ldots \ + x_{n} \cdot v_{n}         \]</span>         è sufficiente fare il prodotto scalare tra <span class="math-span">\( v\)</span> e l'<span class="math-span">\( i\)</span>-esimo vettore della base, ovvero         <span class="math-block">\[             x_{i} = v \star v_{i}         \]</span></div></div><div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostrare ciò, consideriamo la combinazione lineare del vettore <span class="math-span">\( v\)</span> rispetto alla base <span class="math-span">\( B\)</span><span class="math-block">\[             v = x_{1} \cdot v_{1} + \ \ldots \ + x_{i} \cdot v_{i}  + \ \ldots \ + x_{n} \cdot v_{n}         \]</span>         Effettuando il prodotto scalare tra un qualsiasi vettore e l'<span class="math-span">\( i\)</span>-esimo vettore della base <span class="math-span">\( B\)</span>, si avrebbe che         <span class="math-block">\begin{aligned}             &amp; v \star v_{i} = (x_{1} \cdot v_{1} + \ \ldots \ + x_{i} \cdot v_{i}  + \ \ldots \ + x_{n} \cdot v_{n}) \star v_{i}             &amp; \iff         \end{aligned}</span>         che per la linearità del prodotto scalare è         <span class="math-block">\begin{aligned}             &amp;= x_{1} \cdot v_{1} \star v_{i} + \ \ldots \ + x_{i} \cdot v_{i} \star v_{i} + \ \ldots \ + x_{n} \cdot v_{n} \star v_{i}             &amp;          \end{aligned}</span>         Scrivendo in questo modo, è evidente che tutti i prodotto scalari tra vettori si annullano (in quanto sono vettori ortogonali tra loro) ad eccezione del vettore <span class="math-span">\( v_{i}\)</span>, il cui prodotto scalare è per definizione la sua norma (ovvero <span class="math-span">\( 1\)</span>).         <span class="math-block">\begin{aligned}             &amp; x_{i} \cdot v_{i} \star v_{i}             &amp;          \end{aligned}</span>         Ottenendo quindi la <span class="math-span">\( i\)</span>-esima coordinata.     </div></div></div></div><div class="myexample environment" id="example48"><h2 class="environment-title">Esempio - Calcolo delle coordinate di un vettore rispetto ad una base ortonormale</h2><div class="environment-body">     Considerando lo spazio vettoriale euclideo <span class="math-span">\( \mathbb{R}^{2}\)</span> associato al prodotto scalare standard, consideriamo la base ortonormale <span class="math-span">\( B = ((\frac{\sqrt{2}}{2}, \frac{\sqrt{2}}{2}), (\frac{\sqrt{2}}{2}, -\frac{\sqrt{2}}{2}))\)</span>: si vogliono calcolare le coordinate del vettore <span class="math-span">\( (3, 7)\)</span> rispetto a <span class="math-span">\( B\)</span>.      <br/>     Per ottenere la soluzione se non avessimo una base ortonormale, si dovrebbe risolvere il seguente sistema lineare     <span class="math-block">\[         \left\{          \begin{array}{ccccc}             \frac{\sqrt{2}}{2} x_{1} &amp; + &amp; \frac{\sqrt{2}}{2} x_{2} &amp; = &amp; 3  \\             \frac{\sqrt{2}}{2} x_{1} &amp; - &amp; \frac{\sqrt{2}}{2} x_{2} &amp; = &amp; 7  \\         \end{array}         \right.     \]</span>     mentre, grazie al teorema, è possibile calcolare la coordinata come il risultato del prodotto scalare tra i vettori, ovvero     <span class="math-block">\begin{aligned}         &amp; x_{1} = (3, 7) \star (\frac{\sqrt{2}}{2}) = 5 \cdot \sqrt{2} \\         &amp; x_{2} = (3, 7) \star (-\frac{\sqrt{2}}{2}) = -2 \cdot \sqrt{2}     \end{aligned}</span>     che sono esattamente i valori che si otterrebbero dalla risoluzione del sistema </div></div><div class="demonstration environment" id="dem8-6"><h2 class="environment-title">Dimostrazione - Metodo di ortonormalizzazione di Gram-Schmidt</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato</h3><div class="environment-body">         È sempre possibile rendere una qualsiasi base <span class="math-span">\( B = (v_{1}, \ \ldots \ , v_{n})\)</span> ortonormale (ottenendo così la base <span class="math-span">\( B' = (w_{1}, \ \ldots \ , w_{n})\)</span>).          <br/>         Per farlo è necessario considerare il primo vettore <span class="math-span">\( v_{1}\)</span> e renderlo di norma <span class="math-span">\( 1\)</span>, ovvero dividerlo per la sua norma         <span class="math-block">\[             w_{1} = \frac{v_{1}}{||v_{1}||}         \]</span>         A questo punto è necessario rendere i vettori della base ortogonali a <span class="math-span">\( w_{1}\)</span> e per farlo sono necessari due passaggi: il primo è ottenere il vettore <span class="math-span">\( \widehat{w_{k}}\)</span>, che è il vettore ortogonale e poi renderlo di norma <span class="math-span">\( 1\)</span>. Quindi si ha che         <span class="math-block">\[             \left\{             \begin{array}{lcl}                 \widehat{w_{k}} &amp; = &amp; v_{k} - (v_{k} \star w_{k - 1}) w_{k - 1} - \ \ldots \ - (v_{k} \star w_{1}) w_{1}                  \\                 w_{k} &amp; = &amp; \frac{\widehat{w_{k}}}{||\widehat{w_{k}}||}             \end{array}             \right.         \]</span>         Ciò significa che per ottenere il vettore <span class="math-span">\( w_{k}\)</span> è necessario calcolare tutti i vettori <span class="math-span">\( w_{k - 1}, \ \ldots \ , w_{1}\)</span> precedenti.     </div></div><div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         È quindi necessario dimostrare che i vettori <span class="math-span">\( w_{1}, \ \ldots \ , w_{k}\)</span> sono ortogonali a due a due tra loro (<span class="math-span">\( w_{1} \perp w_{2}\)</span>, <span class="math-span">\( w_{1} \perp w_{k}\)</span>), ovvero che il prodotto scalare tra loro è nullo.         <br/>         Per il metodo utilizzato, dire che <span class="math-span">\( w_{1} \perp w_{2}\)</span> è equivalente a dire che <span class="math-span">\( w_{1} \perp \widehat{w_{2}}\)</span>, ovvero         <span class="math-block">\begin{aligned}             &amp; w_{1} \perp w_{2}             &amp; \iff \\             &amp; w_{1} \perp \widehat{w_{2}}              &amp; \iff \\             &amp; w_{1} \perp (v_{2} - (v_{2} \star w_{1}) \cdot w_{1})             &amp; \iff \\             &amp; w_{1} \star (v_{2} - (v_{2} \star w_{1}) \cdot w_{1}) = 0             &amp; \iff         \end{aligned}</span>         che per la linearità del prodotto scalare è uguale a         <span class="math-block">\begin{aligned}             &amp; (w_{1} \star v_{2}) - (v_{2} \star w_{1}) \cdot (w_{1} \star w_{1}) = 0             &amp; \iff         \end{aligned}</span>         Ora, noi sappiamo che <span class="math-span">\( (w_{1} \star w_{1})\)</span> è la norma di <span class="math-span">\( w_{1}\)</span>, il cui valore è proprio <span class="math-span">\( 1\)</span>: ciò significa che nella moltiplicazione si semplifica e rimane la seguente differenza          <span class="math-block">\begin{aligned}             &amp; (w_{1} \star v_{2}) - (v_{2} \star w_{1}) = 0             &amp; \iff         \end{aligned}</span>         che è proprio <span class="math-span">\( 0\)</span> in quanto il prodotto scalare è simmetrico.         <span class="math-block">\begin{aligned}             &amp; 0 = 0             &amp;         \end{aligned}</span>         Tale dimostrazione si può ripetere per tutti gli altri vettori, dimostrando così la proposizione.     </div></div></div></div><div class="myexample environment" id="example49"><h2 class="environment-title">Esempio - Ortonormalizzazione di una base con Gram-Schmidt</h2><div class="environment-body">     Si vuole trovare una base ortonormale per il sottospazio vettoriale di <span class="math-span">\( \mathbb{R}^{3}\)</span> di equazione <span class="math-span">\( x + y + z = 0\)</span>.     <br/>     Innanzitutto troviamo una base, per farlo è sufficiente ottenere la soluzione parametrica dal sistema di sola equazione <span class="math-span">\( x + y + z = 0\)</span>, ovvero     <span class="math-block">\begin{aligned}         \left\{          \begin{array}{ccccccc}             x &amp; + &amp; y &amp; + &amp; z &amp; = &amp; 0         \end{array}         \right.         \qquad         \implies          \qquad         \left\{         \begin{array}{ccccc}             x &amp; = &amp; s \\             y &amp; = &amp; t \\             z &amp; = &amp; -s &amp; - &amp; t         \end{array}         \right.     \end{aligned}</span>     che implica quindi che la soluzione sia      <span class="math-block">\[         \left(         \begin{array}{c}             x \\ y \\ z         \end{array}         \right)         =         s          \cdot         \left(         \begin{array}{c}             1 \\ 0 \\ -1         \end{array}         \right)         +         t         \cdot         \left(         \begin{array}{c}             0 \\ 1 \\ -1         \end{array}         \right)     \]</span>     La base per tale sottospazio è quindi <span class="math-span">\( ((1, 0, -1), (0, 1, -1))\)</span>.     <br/>     Per ottenere una base ortonormale applichiamo Gram-Schmidt. Si ha quindi che la base è composta da due vettori:     <span class="math-block">\begin{aligned}         &amp; v_{1} = (1, 0, -1)         &amp; v_{2} = (0, 1, -1)     \end{aligned}</span>     Iniziamo normalizzando <span class="math-span">\( v_{1}\)</span>, ovvero     <span class="math-block">\[         w_{1} = \frac{v_{1}}{||v_{1}||} = \frac{(1, 0, -1)}{\sqrt{2}} = (\frac{1}{\sqrt{2}}, 0, -\frac{1}{\sqrt{2}})      \]</span>     Ora per ottenere <span class="math-span">\( \widehat{w_{2}}\)</span>, si deve calcolare     <span class="math-block">\[         \begin{array}{lcl}         \widehat{w_{2}} &amp; = &amp; v_{2} - (v_{2} \star w_{1}) \cdot w_{1} \\         &amp; = &amp; (0, 1, -1) - ((0, 1, -1) \star (\frac{1}{\sqrt{2}}, 0, -\frac{1}{\sqrt{2}})) \cdot (\frac{1}{\sqrt{2}}, 0, -\frac{1}{\sqrt{2}}) \\         &amp; = &amp; (0, 1, -1) - (\frac{1}{\sqrt{2}}) \cdot (\frac{1}{\sqrt{2}}, 0, -\frac{1}{\sqrt{2}}) \\         &amp; = &amp; (0, 1, -1) - (\frac{1}{2}, 0, -\frac{1}{2}) \\         &amp; = &amp; (-\frac{1}{2}, 1, -\frac{1}{2})          \end{array}     \]</span>     È semplice ora ottenere <span class="math-span">\( w_{2}\)</span>, ovvero     <span class="math-block">\[         \begin{array}{lcl}             w_{2} &amp; = &amp; \frac{\widehat{w_{2}}}{||\widehat{w_{2}}||} \\             &amp; = &amp; \frac{(-\frac{1}{2}, 1, -\frac{1}{2})}{\sqrt{\frac{3}{2}}} \\             &amp; = &amp; \sqrt{\frac{2}{3}} \cdot (-\frac{1}{2}, 1, -\frac{1}{2})          \end{array}     \]</span>     Si ha quindi la nuova base ortonormale     <span class="math-block">\[         B = \left((\frac{1}{\sqrt{2}}, 0, -\frac{1}{\sqrt{2}}), \sqrt{\frac{2}{3}} \cdot (-\frac{1}{2}, 1, -\frac{1}{2})\right)     \]</span></div></div><div class="demonstration environment" id="dem8-7"><h2 class="environment-title">Dimostrazione - Esistenza di una base ortogonale (e ortonormale) per ogni spazio vettoriale euclideo</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato</h3><div class="environment-body">         Ogni spazio vettoriale euclideo ammette almeno una base ortogonale (e ortonormale).     </div></div><div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Considerando che ogni spazio vettoriale ha diritto ad avere una base e che si può applicare il procedimento di ortonormalizzazione di Gram-Schmidth, si è dimostrato il teorema.     </div></div></div></div><div class="demonstration environment" id="dem8-8"><h2 class="environment-title">Dimostrazione - Lineare indipendenza tra vettori ortogonali</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato</h3><div class="environment-body">         Considerando <span class="math-span">\( n\)</span> vettori <span class="math-span">\( v_{1}, \ \ldots \ , v_{n}\)</span> a due a due ortogonali non nulli, essi sono linearmente indipendenti.     </div></div><div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostare ciò è necessario dimostrare che l'unica combinazione lineare del vettore nullo utilizzando i vettori <span class="math-span">\( v_{1}, \ \ldots \ , v_{n}\)</span> sia quella con solo coordinate nulle, ovvero         <span class="math-block">\begin{aligned}             &amp; x_{1} \cdot v_{1} + \ \ldots \ + x_{n} v_{n} = 0             &amp; \iff          \end{aligned}</span>         Facendo il prodotto scalare tra questi vettori e il vettore <span class="math-span">\( v_{1}\)</span> si ottiene         <span class="math-block">\begin{aligned}             &amp; (x_{1} \cdot v_{1} + \ \ldots \ + x_{n} v_{n}) \star v_{1}  = 0             &amp; \iff          \end{aligned}</span>         e per la linearità del prodotto scalare si ottiene         <span class="math-block">\begin{aligned}             &amp; x_{1} \cdot (v_{1} \star v_{1}) + \ \ldots \ + x_{n} (v_{n} \star v_{1}) = 0             &amp; \iff          \end{aligned}</span>         e, dato che il prodotto scalare tra vettori orgonali è <span class="math-span">\( 0\)</span>, si ha che          <span class="math-block">\begin{aligned}             &amp; x_{1} \cdot (v_{1} \star v_{1}) = 0             &amp; \iff         \end{aligned}</span>         e dato che <span class="math-span">\( v_{1} \star v_{1}\)</span> non può essere nullo per ipotesi, allora abbiamo obbligatoriamente che <span class="math-span">\( x_{1}\)</span> lo deve essere.         <br/>         Ripetendo tale procedimento per ogni vettore, si ha che tutte le coordinate <span class="math-span">\( x_{1}, \ \ldots \ , x_{n}\)</span> sono nulle, dimostrando quindi la lineare indipendenza.     </div></div></div></div><div class="demonstration environment" id="dem8-9"><h2 class="environment-title">Dimostrazione - Teorema di completamento a una base ortogonale (o ortonormale)</h2><div class="environment-body">     Dato il teorema     <div class="proposition environment"><h3 class="environment-title">Enunciato</h3><div class="environment-body">         Se <span class="math-span">\( v_{1}, \ \ldots \ , v_{k}\)</span> sono vettori a due due ortogonali non nulli (e quindi sono linearmente indipendenti), allora è possibile aggiungere dei vettori <span class="math-span">\( v_{k + 1}, \ \ldots \ , v_{n}\)</span> in modo da ottenere una base ortogonale (o ortonormale se la norma di ogni vettore è <span class="math-span">\( 1\)</span>)     </div></div><div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostrare ciò occorre considerare che <span class="math-span">\( v_{1}, \ \ldots \ , v_{k}\)</span> sono linearmente indipendenti. Per il teorema di completamento a una base, è possibile aggiungere altri vettori <span class="math-span">\( v_{k + 1}, \ \ldots \ , v_{n}\)</span>. A questo punto, è possibile applicare Gram-Schmidt per ottenere una base ortogonale (o ortonormale).     </div></div></div></div><div class="definition environment" id="def8-11"><h2 class="environment-title">Definizione - Associazione di ogni prodotto scalare alla matrice identica</h2><div class="environment-body">     Considerando la matrice associata ad un prodotto scalare non standard, si ha che, considerando una base <span class="math-span">\( B_{V} = (v_{1}, \ \ldots \ , v_{n})\)</span> la matrice associata al prodotto scalare è la seguente     <span class="math-block">\[         \left(         \begin{array}{ccc}             f(v_{1}, v_{1}) &amp; \cdots &amp; f(v_{1}, v_{n}) \\             \vdots &amp; \ddots &amp; \vdots \\             f(v_{n}, v_{1}) &amp; \cdots &amp; f(v_{n}, v_{n})         \end{array}         \right)     \]</span>     Nel caso la base sia ortonormale, si ha che il prodotto scalare di vettori diversi è nullo, mentre il prodotto scalare di vettori uguali (ovvero quelli sulla diagonale) è <span class="math-span">\( 1\)</span>, per cui     <span class="math-block">\[         \left(         \begin{array}{ccc}             1 &amp; \cdots &amp; 0 \\             \vdots &amp; \ddots &amp; \vdots \\             0 &amp; \cdots &amp; 1         \end{array}         \right)     \]</span><div class="mynote environment"><h3 class="environment-title">Osservazioni personali - In altre parole</h3><div class="environment-body">         Ciò significa che qualunque prodotto scalare, nel caso si scelga una base ortonormale da cui dipenderanno le coordinate dei due vettori, può essere associato alla matrice identica (ovvero al prodotto scalare standard).     </div></div></div></div><div class="definition environment" id="def8-12"><h2 class="environment-title">Definizione - Complemento ortogonale di un sottospazio vettoriale euclideo</h2><div class="environment-body">     Considerando un sottospazio vettoriale <span class="math-span">\( W\)</span> di uno spazio vettoriale euclideo <span class="math-span">\( V\)</span>, si definisce complemento ortogonale <span class="math-span">\( W^{\perp}\)</span> l'insieme dei vettori di <span class="math-span">\( V\)</span> che sono ortogonali a tutti i vettori di <span class="math-span">\( W\)</span>, ovvero     <span class="math-block">\[         W^{\perp} = \{          v \in V          \quad : \quad         v \star w = 0 \quad         \forall w \in W \}     \]</span></div></div><div class="demonstration environment" id="dem8-10"><h2 class="environment-title">Dimostrazione - Complemento ortogonale come sottospazio vettoriale</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato</h3><div class="environment-body">         Il complemento ortogonale di un sottospazio vettoriale <span class="math-span">\( W\)</span> di <span class="math-span">\( V\)</span> (<span class="math-span">\( W^{\perp}\)</span>), è anch'esso un sottospazio vettoriale di <span class="math-span">\( V\)</span>.      </div></div><div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per verificare tale proposizione è necessario dimostrare che dati i vettori <span class="math-span">\( u_{1}, u_{2} \in W^{\perp}\)</span>, la loro somma e il prodotto per uno scalare sia interna a <span class="math-span">\( W\)</span>, ovvero per ogni <span class="math-span">\( w \in W\)</span><span class="math-block">\[             w \star (\alpha \cdot u_{1} + \beta \cdot u_{2}) = 0         \]</span>         Partendo quindi da          <span class="math-block">\begin{aligned}             &amp; w \star (\alpha \cdot u_{1} + \beta \cdot u_{2})             &amp; \iff         \end{aligned}</span>         e applicando la linearità si ottiene         <span class="math-block">\begin{aligned}             &amp; \alpha \cdot (w \star u_{1}) + \beta \cdot (w \star u_{2}) = 0             &amp;          \end{aligned}</span>         che è uguale a <span class="math-span">\( 0\)</span> in quanto <span class="math-span">\( u_{1}\)</span> e <span class="math-span">\( u_{2}\)</span> appartengono già a <span class="math-span">\( W^{\perp}\)</span> e il prodotto scalare con <span class="math-span">\( w\)</span> è nullo.     </div></div></div></div><div class="definition environment" id="def8-13"><h2 class="environment-title">Definizione - Calcolare una base per il complemento ortogonale di un sottospazio vettoriale</h2><div class="environment-body">     Dato che il complemento ortogonale <span class="math-span">\( W^{\perp}\)</span> di un sottospazio vettoriale <span class="math-span">\( W\)</span> è anch'esso un sottospazio vettoriale, esso ammette una base. Per trovarla è quindi sufficiente imporre la definizione di complemento ortogonale ad un generico vettore <span class="math-span">\( v \in V\)</span> rispetto a tutti i vettori della base <span class="math-span">\( B_{W} (w_{1}, \ \ldots \ , w_{n})\)</span>  e risolvere il sistema lineare che ne deriva, ovvero     <span class="math-block">\[         \left\{         \begin{array}{ccccc}             v &amp; \star &amp; w_{1} &amp; = &amp; 0 \\             \vdots &amp;  &amp; \\             v &amp; \star &amp; w_{n} &amp; = &amp; 0         \end{array}         \right.     \]</span></div></div><div class="myexample environment" id="example50"><h2 class="environment-title">Esempio - Calcolo di una base per il complemento ortogonale di un sottospazio vettoriale</h2><div class="environment-body">     Considerando un sottospazio vettoriale <span class="math-span">\( W\)</span> di <span class="math-span">\( \mathbb{R}^{3}\)</span> generato dalla base <span class="math-span">\( B_{W} = ((1,2,3), (2, 2, 2))\)</span>. Utilizzando il prodotto vettoriale standard <span class="math-span">\( \star\)</span> e un generico vettore <span class="math-span">\( v = (x_{1}, x_{2}, x_{3})\)</span>, imponiamo le seguenti relazioni     <span class="math-block">\[         \left\{         \begin{array}{ccccc}            (x_{1}, x_{2}, x_{3}) &amp; \star &amp; (1, 2, 3) &amp; = &amp; 0  \\            (x_{1}, x_{2}, x_{3}) &amp; \star &amp; (2, 2, 2) &amp; = &amp; 0         \end{array}         \right.     \]</span>     che genera il seguente sistema lineare     <span class="math-block">\[         \left\{         \begin{array}{ccccccc}             1 x_{1} &amp; + &amp; 2 x_{2} &amp; + &amp; 3 x_{3} &amp; = &amp; 0 \\             2 x_{1} &amp; + &amp; 2 x_{2} &amp; + &amp; 2 x_{3} &amp; = &amp; 0         \end{array}         \right.     \]</span>     la cui soluzione parametrica è     <span class="math-block">\[         \left\{         \begin{array}{ccccccc}             x &amp; = &amp; t \\             y &amp; = &amp; -2t \\             z &amp; = &amp; t \\         \end{array}         \right.         \quad         \implies         \quad         \left(         \begin{array}{c}             x \\ y \\ z         \end{array}         \right)         =         t \cdot         \left(         \begin{array}{c}             1 \\ 2 \\ 1         \end{array}         \right)     \]</span>     Dunque si ottiene che una base per il complemento ortogonale del sottospazio vettoriale è <span class="math-span">\( B_{W^{\perp}} = ((1, 2, 1))\)</span>.     <div class="mynote environment"><h3 class="environment-title">Osservazioni personali - Nel caso di altri prodotti scalare</h3><div class="environment-body">         In questo esempio si è utilizzato il prodotto scalare standard per semplificare i calcoli: nel caso si utilizzasse un altro prodotto scalare cambierebbe solo la generazione del sistema lineare.     </div></div><div class="mynote environment"><h3 class="environment-title">Osservazioni personali - Nel caso si esprimano i vettori rispetto a basi non canoniche</h3><div class="environment-body">         In questo caso tutti i vettori sono espressi rispetto alla base canonica di <span class="math-span">\( \mathbb{R}^{3}\)</span>: nel caso si utilizzasse una base diversa, cambierebbe la forma di un generico vettore <span class="math-span">\( v\)</span>, calcolabile, considerando una base non canonica <span class="math-span">\( B = (b_{1}, b_{2}, b_{3})\)</span> nel seguente modo:         <span class="math-block">\[             v = x_{1} \cdot b_{1} + x_{2} \cdot b_{2} + x_{3} \cdot b_{3}         \]</span></div></div></div></div><div class="demonstration environment" id="dem8-11"><h2 class="environment-title">Dimostrazione - Dimensione del complemento ortogonale di un sottospazio vettoriale</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato</h3><div class="environment-body">         La dimensione del complemento ortogonale <span class="math-span">\( W^{\perp}\)</span> di un sottospazio vettoriale <span class="math-span">\( W\)</span> dello spazio vettoriale euclideo <span class="math-span">\( V\)</span> è dipendente dalle dimensioni di <span class="math-span">\( W\)</span> e <span class="math-span">\( V\)</span>, ovvero         <span class="math-block">\[             dim(W^{\perp}) = dim(V) - dim(W)         \]</span></div></div><div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Considerando una base ortonormale <span class="math-span">\( B_{W} = (w_{1}, \ \ldots \ , w_{k})\)</span> di <span class="math-span">\( k\)</span> vettori per <span class="math-span">\( W\)</span>, per il teorema di completamento ad una base ortonormale, è possibile ottenere una base <span class="math-span">\( B_{V}\)</span> per <span class="math-span">\( V\)</span> composta da <span class="math-span">\( n\)</span> vettori         <span class="math-block">\[             B_{V} = (w_{1}, \ \ldots \ , w_{k}, w_{k + 1}, \ \ldots \ , w_{n})         \]</span>         Per dimostrare la proposizione, è sufficiente dimostrare che i vettori (<span class="math-span">\( w_{k + 1}, \ \ldots \ , w_{n}\)</span>) siano una base ortonormale per <span class="math-span">\( W^{\perp}\)</span>.         <br/>         Innanzitutto, sappiamo che ogni vettore (<span class="math-span">\( w_{k + 1}, \ \ldots \ , w_{n}\)</span>) appartiene a <span class="math-span">\( W^{\perp}\)</span> in quanto sono ortogonali a tutti i vettori di <span class="math-span">\( W\)</span> (grazie al fatto che abbiamo considerato una base ortonormale) e che sono linearmente indipendenti (in quanto sono ortogonali tra loro).          <br/>         È quindi necessario dimostrare che i vettori  (<span class="math-span">\( w_{k + 1}, \ \ldots \ , w_{n}\)</span>) siano un sistema di generatori per <span class="math-span">\( W^{\perp}\)</span>. Per farlo consideriamo che <span class="math-span">\( W^{\perp}\)</span> è un sottospazio vettoriale di <span class="math-span">\( V\)</span>, allora è possibile esprimere un qualsiasi vettore <span class="math-span">\( u \in W^{\perp}\)</span> come combinazione lineare di <span class="math-span">\( B_{V}\)</span>, ovvero         <span class="math-block">\[             u = x_{1} \cdot w_{1} + \ \ldots \ + x_{k} \cdot w_{k} + x_{k + 1} \cdot w_{k + 1} + \ \ldots \ + x_{n} \cdot w_{n}         \]</span>         Ora, è sufficiente dimostrare che le coordinate <span class="math-span">\( (x_{1}, \ \ldots \ , x_{k})\)</span> sono nulle (perchè ciò significa che non contribuiscono alla combinazione lineare dei vettori di <span class="math-span">\( W^{\perp}\)</span>)         Per definizione, si ha che <span class="math-span">\( u \star w_{i} = 0\)</span> (ovvero che il prodotto tra <span class="math-span">\( u\)</span> e i vettori <span class="math-span">\( (w_{1}, \ \ldots \ , w_{k})\)</span> è <span class="math-span">\( 0\)</span>) e sappiamo che il prodotto scalare tra un vettore e un vettore di una base ortonormale fornisce la coordinata associata a tale vettore (rispetto a tale base ortonormale): sappiamo quindi che le coordinate <span class="math-span">\( x_{1}, \ \ldots \ , x_{k}\)</span> (ovvero quelle associate ai vettori di <span class="math-span">\( B_{W}\)</span>) sono tutte nulle. Quindi, è possibile scrivere <span class="math-span">\( u\)</span> come         <span class="math-block">\[             u = x_{k + 1} \cdot w_{k + 1} + \ \ldots \ + x_{n} \cdot w_{n}         \]</span>         combinazione lineare dei vettori <span class="math-span">\( w_{k + 1}, \ \ldots \ , w_{n}\)</span>.         <br/>         Si è dimostrato che tali vettori sono una base per <span class="math-span">\( W^{\perp}\)</span>.     </div></div></div></div><div class="demonstration environment" id="dem8-12"><h2 class="environment-title">Dimostrazione - Complemento ortogonale del complemento ortogonale</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato</h3><div class="environment-body">         Il complemento ortogonale <span class="math-span">\( (W^{\perp})^{\perp}\)</span> del complemento ortogonale <span class="math-span">\( W^{\perp}\)</span> del sottospazio vettoriale <span class="math-span">\( W\)</span> è il sottospazio vettoriale <span class="math-span">\( W\)</span>, ovvero         <span class="math-block">\[             (W^{\perp})^{\perp} = W         \]</span></div></div><div class="mynote environment"><h3 class="environment-title">Osservazioni personali - In altre parole</h3><div class="environment-body">         Ciò significa che l'insieme dei vettori di <span class="math-span">\( V\)</span> che sono ortogonali a tutti i vettori di <span class="math-span">\( W^{\perp}\)</span> sono i vettori di <span class="math-span">\( W\)</span>.     </div></div><div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Dimostrare tale proposizione significa dimostrare che <span class="math-span">\( W\)</span> e <span class="math-span">\( (W^{\perp})^{\perp}\)</span> sono lo stesso spazio vettoriale: per farlo è sufficiente dimostrare che una base per <span class="math-span">\( W\)</span> è equivalente a una base per <span class="math-span">\( (W^{\perp})^{\perp}\)</span>.         <br/>         Per farlo consideriamo una base ortonormale <span class="math-span">\( B_{W} = (w_{1}, \ \ldots \ , w_{k})\)</span> e completiamola ad una base ortonormale per <span class="math-span">\( B_{V}\)</span>, ovvero otteniamo la base         <span class="math-block">\[             B_{V} = (w_{1}, \ \ldots \ , w_{k}, w_{k + 1}, \ \ldots \ , w_{n})         \]</span>         Per definizione, sappiamo quindi che i vettori aggiunti sono vettori linearmente indipendenti e ortogonali a tutti i vettori di <span class="math-span">\( B_{W}\)</span>, inoltre sono esattamente <span class="math-span">\( n - k\)</span> che è esattamente la dimensione del complemento ortogonale (ovvero <span class="math-span">\( dim(W^{\perp}) = dim(V) - dim(W) = n - k\)</span>): per questo motivo possiamo dire che sono una base per <span class="math-span">\( W^{\perp}\)</span>.         <br/>         Ora considerando <span class="math-span">\( U = W^{\perp}\)</span>, per dimostrare la proposizione è necessario cercare <span class="math-span">\( U^{\perp}\)</span>. Sempre considerando la relazione <span class="math-span">\( dim(U^{\perp}) = dim(V) - dim(U)\)</span> otteniamo che <span class="math-span">\( dim(U^{\perp}) = n - (n - k) = k\)</span>: è sufficiente quindi trovare <span class="math-span">\( k\)</span> vettori ortogonali (in quanto l'ortogonalità implica la lineare indipendenza) tra loro. Ricordando che la base <span class="math-span">\( B_{W}\)</span> contiene <span class="math-span">\( k\)</span> vettori ortogonali tra loro, possiamo dire che <span class="math-span">\( B_{W} = B_{U^{\perp}}\)</span> che dimostra la proposizione.      </div></div></div></div><div class="definition environment" id="def8-14"><h2 class="environment-title">Definizione - Matrice ortogonale</h2><div class="environment-body">     Una matrice <span class="math-span">\( A = M_{n \times n}(\mathbb{R})\)</span> si dice ortogonale se la sua inversa coincide con la sua trasposta, ovvero     <span class="math-block">\[         {}^{t} \! A \odot A = I     \]</span>     Le matrici ortogonali sono anche le matrici le cui colonne (o le righe) sono le coordinate dei vettori di una base ortonormale.  </div></div><div class="myexample environment" id="example51"><h2 class="environment-title">Esempio - Esempio di matrice ortogonale</h2><div class="environment-body">     La matrice <span class="math-span">\( 3 \times 3\)</span><span class="math-block">\[         \left(         \begin{array}{ccc}            \frac{1}{3}  &amp; \frac{2}{3} &amp; \frac{2}{3} \\            \frac{2}{3}  &amp; \frac{1}{3} &amp; -\frac{2}{3} \\            -\frac{2}{3}  &amp; \frac{2}{3} &amp; -\frac{1}{3}         \end{array}         \right)     \]</span>     è ortogonale, infatti considerando la sua trasposta     <span class="math-block">\[         \left(         \begin{array}{ccc}            \frac{1}{3}  &amp; \frac{2}{3} &amp; -\frac{2}{3} \\            \frac{2}{3}  &amp; \frac{1}{3} &amp; \frac{2}{3} \\            \frac{2}{3}  &amp; -\frac{2}{3} &amp; -\frac{1}{3}         \end{array}         \right)     \]</span>     si ha che     <span class="math-block">\[         \left(         \begin{array}{ccc}            \frac{1}{3}  &amp; \frac{2}{3} &amp; \frac{2}{3} \\            \frac{2}{3}  &amp; \frac{1}{3} &amp; -\frac{2}{3} \\            -\frac{2}{3}  &amp; \frac{2}{3} &amp; -\frac{1}{3}         \end{array}         \right)         \odot          \left(         \begin{array}{ccc}            \frac{1}{3}  &amp; \frac{2}{3} &amp; -\frac{2}{3} \\            \frac{2}{3}  &amp; \frac{1}{3} &amp; \frac{2}{3} \\            \frac{2}{3}  &amp; -\frac{2}{3} &amp; -\frac{1}{3}         \end{array}         \right)         =          \left(         \begin{array}{ccc}            1 &amp; 0 &amp; 0 \\            0 &amp; 1 &amp; 0 \\            0 &amp; 0 &amp; 1         \end{array}         \right)     \]</span></div></div><div class="demonstration environment" id="dem8-13"><h2 class="environment-title">Dimostrazione - Determinante di una matrice ortogonale</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato</h3><div class="environment-body">         Il determinante di una matrice ortogonale <span class="math-span">\( A\)</span> è <span class="math-span">\( \pm 1\)</span>, ovvero         <span class="math-block">\[             det(A) = \pm 1         \]</span></div></div><div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostrare questa proposizione, consideriamo che <span class="math-span">\( 1\)</span> è il determinante della matrice identica, ovvero         <span class="math-block">\begin{aligned}             &amp; 1 = det(I)             &amp; \iff         \end{aligned}</span>         e, dato che <span class="math-span">\( A\)</span> è ortogonale, è possibile scrivere la matrice identica come         <span class="math-block">\begin{aligned}             &amp; det(A \odot {}^{t} \! A)             &amp; \iff         \end{aligned}</span>         e per Binet         <span class="math-block">\begin{aligned}             &amp; det(A) \cdot det({}^{t} \! A)              &amp; \iff         \end{aligned}</span>         Ricordandosi che il determinante di una matrice è uguale a quello della sua trasposta, si ottiene che         <span class="math-block">\begin{aligned}            &amp; det(A) \cdot det(A) = (det(A))^{2}            &amp; \iff         \end{aligned}</span>         e paragonando il risultato con il valore di partenza si ottiene         <span class="math-block">\begin{aligned}             &amp; 1 = (det(A))^{2}             &amp; \iff \\             &amp; \pm 1 = det(A)         \end{aligned}</span>         ovvero che il determinante di una matrice ortogonale può essere solo <span class="math-span">\( \pm 1\)</span>.     </div></div></div></div><div class="definition environment" id="def8-15"><h2 class="environment-title">Definizione - Matrici ortogonalmente diagonalizzabili</h2><div class="environment-body">     Una matrice <span class="math-span">\( A \in M_{n \times n}(\mathbb{R})\)</span> si dice ortogonalmente diagonalizzabile se esiste una matrice <span class="math-span">\( E\)</span> tale che <span class="math-span">\( {}^{t} E \odot A \odot E\)</span> è diagonale.  </div></div><div class="definition environment" id="def8-16"><h2 class="environment-title">Definizione - Teorema spettrale</h2><div class="environment-body">     Una matrice <span class="math-span">\( A \in M_{n \times n}(\mathbb{R})\)</span> è ortogonalmente diagonalizzabile se e solo se è simmetrica. </div></div><div class="definition environment" id="def8-17"><h2 class="environment-title">Definizione - Isometria</h2><div class="environment-body">     Un'isometria è un'applicazione lineare <span class="math-span">\( f: V \to V\)</span>, dove <span class="math-span">\( V\)</span> è uno spazio vettoriale euclideo che conserva il prodotto scalare tra vettori, ovvero, dati <span class="math-span">\( v, w \in V\)</span><span class="math-block">\[         v \star w = f(v) \star f(w)     \]</span>     Ciò significa che ogni isometria conserva angoli e norme.     <div class="mynote environment"><h3 class="environment-title">Osservazioni personali - Esempi di isometrie</h3><div class="environment-body">         Le isometrie sono le applicazioni lineari che rappresentano i movimenti rigidi nello spazio.     </div></div></div></div><div class="demonstration environment" id="dem8-14"><h2 class="environment-title">Dimostrazione - Matrice associata ad una isometria</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato</h3><div class="environment-body">         La matrice associata ad un'isometria <span class="math-span">\( f: V \to V\)</span> è ortogonale.     </div></div><div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Per dimostrare ciò, consideriamo la matrice <span class="math-span">\( A \in M_{n \times n}(\mathbb{R})\)</span> associata all'isometria <span class="math-span">\( f: V \to V\)</span>, le coordinate di due vettori <span class="math-span">\( x = (x_{1}, \ \ldots \ , x_{n})\)</span> e <span class="math-span">\( y = (y_{1}, \ \ldots \ , y_{n})\)</span>, si avrà che l'immagine dei due vettori può essere così scritta         <span class="math-block">\begin{aligned}             &amp; f(x) = A \odot {}^{t} \! x             &amp; f(y) = A \odot {}^{t} \! y         \end{aligned}</span>         Dove <span class="math-span">\( x\)</span> e <span class="math-span">\( y\)</span> sono trasposti per poterli moltiplicare alla matrice <span class="math-span">\( A\)</span>. Tuttavia, le immagini risultano essere vettori colonna mentre per fare il prodotto è necessario che <span class="math-span">\( f(x)\)</span> sia un vettore riga. Ciò significa che si deve trasporre <span class="math-span">\( f(x)\)</span> per cui si ottiene          <span class="math-block">\begin{aligned}             &amp; {}^{t} \! (A \odot {}^{t} \! x) = x \odot {}^{t} \! A         \end{aligned}</span>         Dunque, ricordando che ogni prodotto scalare può essere associato alla matrice identica (se si scelgono le basi giuste), si ha che la definizione di isometria può essere così scritta         <span class="math-block">\[              x \odot {}^{t} \! A \odot A \odot {}^{t} \! y = x \odot I \odot {}^{t} \! y         \]</span>         Ciò può avvenire se e solo se <span class="math-span">\( {}^{t} \! A \odot A = I\)</span>, ovvero se e solo se <span class="math-span">\( A^{-1} = {}^{t} \! A\)</span> (che è la definizione di matrice ortogonale). Ciò significa che le matrici associate alle isometrie sono esattamente le matrici ortogonali.     </div></div></div></div><div class="mynote environment"><h3 class="environment-title">Osservazioni personali - Basi ortonormali di <span class="math-span">\( \mathbb{R}^{2}\)</span></h3><div class="environment-body">     Considerando un qualsiasi vettore di norma <span class="math-span">\( 1\)</span>, le sue coordinate in funzione dell'angolo <span class="math-span">\( \theta\)</span> sono     <span class="math-block">\[         v_{1} = (\cos(\theta), \sin(\theta))     \]</span>     Il vettore <span class="math-span">\( v_{2}\)</span> deve essere ortogonale a <span class="math-span">\( v_{1}\)</span> e le possibilità sono che l'angolo di <span class="math-span">\( v_{2}\)</span> sia <span class="math-span">\( \theta \pm \frac{\pi}{2}\)</span>. Avremo quindi     <span class="math-block">\begin{aligned}         \text{se } \theta + \frac{\pi}{2}         \quad \implies \quad         v_{2} = (\cos(\theta + \frac{\pi}{2}), \sin(\theta + \frac{\pi}{2}))         \\         \text{se } \theta - \frac{\pi}{2}         \quad \implies \quad         v_{2} = (\cos(\theta - \frac{\pi}{2}), \sin(\theta - \frac{\pi}{2}))     \end{aligned}</span>     che, ricordandosi gli angoli associati, è come scrivere     <span class="math-block">\begin{aligned}         \text{se } \theta + \frac{\pi}{2}         \quad &amp;\implies \quad         v_{2} = (-\sin(\theta), \cos(\theta))         \\         \text{se } \theta - \frac{\pi}{2}         \quad &amp;\implies \quad         v_{2} = (\sin(\theta), -\cos(\theta))     \end{aligned}</span>     Dunque, avremo che tutte le possibili basi ortonormali di <span class="math-span">\( \mathbb{R}^{2}\)</span> sono      <span class="math-block">\begin{aligned}         &amp; B_{1} = ((\cos(\theta), \sin(\theta)), (-\sin(\theta), \cos(\theta)))         \\         &amp; B_{2} = ((\cos(\theta), \sin(\theta)), (\sin(\theta), -\cos(\theta)))     \end{aligned}</span>     e le relative matrici ortogonali sono     <span class="math-block">\[         \left(         \begin{array}{cc}             \cos(\theta) &amp; \sin(\theta) \\             -\sin(\theta) &amp; \cos(\theta)         \end{array}         \right)     \]</span>     che rappresentano la rotazione di <span class="math-span">\( \theta\)</span> radianti nel piano e le matrici      <span class="math-block">\[         \left(         \begin{array}{cc}             \cos(\theta) &amp; \sin(\theta) \\             \sin(\theta) &amp; -\cos(\theta)         \end{array}         \right)     \]</span>     che rappresentano la rotazione di <span class="math-span">\( \theta\)</span> radianti nel piano e la simmetria di una retta passante per l'origine. </div></div><div class="demonstration environment" id="dem8-15"><h2 class="environment-title">Dimostrazione - 1 autovalore di ogni matrice <span class="math-span">\( n \times n\)</span> ortogonale, con determinante positivo e <span class="math-span">\( n\)</span> dispari</h2><div class="environment-body">     Data la proposizione     <div class="proposition environment"><h3 class="environment-title">Enunciato</h3><div class="environment-body">         Considerando una matrice <span class="math-span">\( A \in M_{n \times n}(\mathbb{R})\)</span> ortogonale, con il determinante positivo (<span class="math-span">\( det(A) \gt 0\)</span>) e <span class="math-span">\( n\)</span> dispari, allora un autovalore di <span class="math-span">\( A\)</span> è <span class="math-span">\( 1\)</span>.     </div></div><div class="proof environment"><h3 class="environment-title">Dimostrazione:<span class="material-symbols-outlined body-visibility-icon" onclick="toggle_proof(event)">visibility_off</span></h3><div class="environment-body hyde">         Dimostrare che <span class="math-span">\( 1\)</span> è autovalore di <span class="math-span">\( A\)</span>, significa dire che il polinomio caratterisco di <span class="math-span">\( A\)</span> con <span class="math-span">\( \lambda = 1\)</span> è uguale a <span class="math-span">\( 0\)</span>, ovvero         <span class="math-block">\begin{aligned}             &amp; p_{A}(1) = 0             &amp; \iff         \end{aligned}</span>         che è equivalente a scrivere         <span class="math-block">\begin{aligned}             &amp; 0 = det(A - 1 \cdot I)             &amp; \iff         \end{aligned}</span>         Allora, ricordando che la trasposta di una matrice ortogonale è anche la sua inversa, è possibile scrivere         <span class="math-block">\begin{aligned}             &amp; det(A - A \odot {}^{t} \! A)             &amp; \iff         \end{aligned}</span>         e raccogliendo <span class="math-span">\( A\)</span> si può ottenere          <span class="math-block">\begin{aligned}             &amp; det(A \odot (I - {}^{t} \! A)             &amp; \iff         \end{aligned}</span>         e per Binet         <span class="math-block">\begin{aligned}             &amp; det(A) \cdot det(I - {}^{t} \! A)             &amp; \iff         \end{aligned}</span>         e, dato che il determinante di una matrice ortogonale può essere solo <span class="math-span">\( \pm 1\)</span>, e che per ipotesi il determinante è positivo, si ha che il <span class="math-span">\( det(A) = 1\)</span>, quindi è equivalente scrivere         <span class="math-block">\begin{aligned}             &amp; det(I - {}^{t} \! A)             &amp; \iff         \end{aligned}</span>         Dato che il determinante di una matrice trasposta non cambia, si può trasporre la matrice <span class="math-span">\( A - I\)</span> (che è uguale alla differenza delle trasposte), quindi         <span class="math-block">\begin{aligned}             &amp; det({}^{t} \! (I - {}^{t} \! A))             &amp; \iff \\             &amp; det(I - A)              &amp; \iff         \end{aligned}</span>          e raccogliendo <span class="math-span">\( -1\)</span> si ottiene         <span class="math-block">\begin{aligned}             &amp; det(-(A - I))             &amp; \iff         \end{aligned}</span>          Ricordando che la moltiplicazione di una qualsiasi matrice per <span class="math-span">\( -1\)</span> inverte il determinante, possiamo vedere <span class="math-span">\( -(A - I)\)</span> come la moltiplicazione di <span class="math-span">\( n\)</span> volte per <span class="math-span">\( -1\)</span>, per cui scrivere <span class="math-span">\( det(-(A - I))\)</span> è come scrivere         <span class="math-block">\begin{aligned}             &amp; (-1)^{n} \cdot det(A - I)             &amp; \iff         \end{aligned}</span>          Nel caso quindi <span class="math-span">\( n\)</span> sia dispari, avremmo che         <span class="math-block">\[             det(A - I) = -det(A - I)         \]</span>         ovvero che i due determinanti sono uguali, ovvero che il determinante è nullo. Si è quindi dimostrato che <span class="math-span">\( 1\)</span> è autovalore.     </div></div><div class="mynote environment"><h3 class="environment-title">Osservazioni personali - Una visione sul mondo</h3><div class="environment-body">         Dire che <span class="math-span">\( 1\)</span> è un autovalore, significa dire che esiste un vettore la cui immagine è sè stesso per ogni isometria associata ad una matrice con <span class="math-span">\( n\)</span> dispari.     </div></div></div></div>
            </article>
            <nav class="buttons-container content-width">
                <a class="navigation-button previous" href="forme-bilineari-e-prodotto-scalare.html" rel="nofollow"><span>Forme bilineari e prodotto scalare</span></a>
                <a class="navigation-button next" href="../geometria-analitica-nello-spazio/index.html" rel="nofollow"><span>Geometria analitica nello spazio</span></a>
            </nav>
        </section>
        <div class="scroll-to-bottom-button" onclick="scroll_to_bottom()">
            <span class="material-symbols-outlined">
                keyboard_double_arrow_down
            </span>
        </div>
        <footer class="footer-wrapper">
            <div class="copyright-wrapper">
                <span> &copy; Copyright 2023</span> /
                <span>made by lorenzoarlo</span>
            </div>
            /
            <div class="privacy-wrapper">
                <span><a href="https://lorenzoarlo.github.io/privacy-and-cookies/" rel="nofollow">Pannello preferenze cookie</a></span> /
                <span><a href="https://lorenzoarlo.github.io/privacy-and-cookies/privacy-policy.html" rel="nofollow" target="_blank" >Privacy Policy</a></span>
            </div>
        </footer>
    </div>
</body>
</html>